{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @name graph_v3.2_v20190616\n",
    "# @description notebook to build the NGLY1 Deficiency review knowledge graph v3.2\n",
    "# @author Núria Queralt Rosinach\n",
    "# @date 16 June 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "This is the notebook for the creation of the first review network and derived hypotheses. \n",
    "\n",
    "* Using intermediary variables from workflow objects. In this workflow variables are directly used for the next step. \n",
    "\n",
    "\n",
    "* Review network: From Monarch knowledge graph, we built a network seeded by 8 nodes, retrieving their explicit relationships and all the relationships among all these nodes. Seed nodes:\n",
    "\n",
    "    - 'MONDO:0007739' HD\n",
    "    - 'HGNC:4851' Htt\n",
    "    - 'CHEBI:18248' Iron (not working)\n",
    "    - 'HGNC:18229' Rhes (RASD2)\n",
    "    \n",
    "Possible seed nodes:\n",
    "https://monarchinitiative.org/search/Iron\n",
    "* Connecting paths: query templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transcriptomics, regulation, curation, monarch, graph, neo4jlib, hypothesis, summary, utils\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edges library\n",
    "### Review edges to integrate into the knowledge graph and prepare them as individual networks\n",
    "\n",
    "#### TRANSCRIPTOMICS NETWORK\n",
    "#### import transcriptomics\n",
    "We retrieved edges from RNA-seq transcriptomics profiles using the `transcriptomics` module:\n",
    "\n",
    "    - Experimental data sets: from Chow et al. paper [pmid:29346549] (NGLY1 deficiency model on fruit fly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The function \"read_data()\" is running...\n",
      "\n",
      "* This is the size of the raw expression data structure: (28087, 10)\n",
      "* These are the expression attributes: Index(['Unnamed: 0', 'symbol', 'baseMean', 'HD.mean', 'Control.mean',\n",
      "       'log2FoldChange', 'lfcSE', 'stat', 'pvalue', 'padj'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "           Unnamed: 0 symbol  baseMean    HD.mean  Control.mean  \\\n",
      "0  ENSG00000069011.10  PITX1  5.645675  18.684286      0.323793   \n",
      "\n",
      "   log2FoldChange     lfcSE      stat        pvalue          padj  \n",
      "0        4.769658  0.366367  13.01879  9.567529e-39  2.687232e-34  \n",
      "\n",
      "The raw data is saved at: /home/karolis/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer/transcriptomics/HD/data/GSE64810_mlhd_DESeq2_diffexp_DESeq2_outlier_trimmed_adjust.csv\n",
      "\n",
      "\n",
      "Finished read_data().\n",
      "\n",
      "CPU times: user 40.4 ms, sys: 4.97 ms, total: 45.4 ms\n",
      "Wall time: 49 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# prepare data to graph schema\n",
    "csv_path = './transcriptomics/GSE64810_mlhd_DESeq2_diffexp_DESeq2_outlier_trimmed_adjust.txt'\n",
    "data = transcriptomics.read_data(csv_path, \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The function \"read_data()\" is running...\n",
      "\n",
      "* This is the size of the raw expression data structure: (28087, 10)\n",
      "* These are the expression attributes: Index(['Unnamed: 0', 'symbol', 'baseMean', 'HD.mean', 'Control.mean',\n",
      "       'log2FoldChange', 'lfcSE', 'stat', 'pvalue', 'padj'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "           Unnamed: 0 symbol  baseMean    HD.mean  Control.mean  \\\n",
      "0  ENSG00000069011.10  PITX1  5.645675  18.684286      0.323793   \n",
      "\n",
      "   log2FoldChange     lfcSE      stat        pvalue          padj  \n",
      "0        4.769658  0.366367  13.01879  9.567529e-39  2.687232e-34  \n",
      "\n",
      "The raw data is saved at: /home/karolis/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer/transcriptomics/HD/data/GSE64810_mlhd_DESeq2_diffexp_DESeq2_outlier_trimmed_adjust.csv\n",
      "\n",
      "\n",
      "Finished read_data().\n",
      "\n",
      "\n",
      "The function \"clean_data()\" is running. Keeping only data with FC > 1.5 and FDR < 5% ...\n",
      "\n",
      "* This is the size of the clean expression data structure: (3209, 6)\n",
      "* These are the clean expression attributes: Index(['EnsembleID', 'symbol', 'log2FoldChange', 'pvalue', 'padj',\n",
      "       'Regulation'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "           EnsembleID symbol  log2FoldChange        pvalue          padj  \\\n",
      "0  ENSG00000069011.10  PITX1        4.769658  9.567529e-39  2.687232e-34   \n",
      "\n",
      "    Regulation  \n",
      "0  Upregulated  \n",
      "\n",
      "The clean data is saved at: /home/karolis/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer/transcriptomics/HD/out/Transcriptome_human_BA9.csv\n",
      "\n",
      "\n",
      "Finished clean_data().\n",
      "\n",
      "\n",
      "The function \"prepare_data_edges()\" is running...\n",
      "\n",
      "* This is the size of the expression data structure: (3209, 13)\n",
      "* These are the expression attributes: Index(['ensemble_id', 'symbol', 'log2FoldChange', 'pvalue', 'padj',\n",
      "       'regulation', 'source', 'subject_id', 'subject_label', 'property_id',\n",
      "       'property_label', 'reference_id', 'object_id'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "          ensemble_id symbol  log2FoldChange        pvalue          padj  \\\n",
      "0  ENSG00000069011.10  PITX1        4.769658  9.567529e-39  2.687232e-34   \n",
      "\n",
      "    regulation source               subject_id subject_label property_id  \\\n",
      "0  Upregulated   Chow  ensembl:ENSG00000197386           HTT  RO:0002434   \n",
      "\n",
      "   property_label   reference_id                object_id  \n",
      "0  interacts with  PMID:26636579  ensembl:ENSG00000069011  \n",
      "\n",
      "The HD BA9 transcriptomics expression edges are saved at: /home/karolis/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer/transcriptomics/HD/out/Transcriptome_human_BA9_edges.csv\n",
      "\n",
      "\n",
      "Finished prepare_data_edges().\n",
      "\n",
      "\n",
      "The function \"prepare_rna_edges()\" is running...\n",
      "\n",
      "* This is the size of the edges data structure: (3209, 12)\n",
      "* These are the edges attributes: Index(['subject_id', 'subject_label', 'property_id', 'property_label',\n",
      "       'object_id', 'object_label', 'log2FoldChange', 'pvalue', 'fdr',\n",
      "       'regulation', 'source', 'reference_id'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "                subject_id subject_label property_id  property_label  \\\n",
      "0  ensembl:ENSG00000197386           HTT  RO:0002434  interacts with   \n",
      "\n",
      "                 object_id object_label  log2FoldChange        pvalue  \\\n",
      "0  ensembl:ENSG00000069011        PITX1        4.769658  9.567529e-39   \n",
      "\n",
      "            fdr   regulation source   reference_id  \n",
      "0  2.687232e-34  Upregulated   Chow  PMID:26636579  \n",
      "\n",
      "This data object is not saved.\n",
      "\n",
      "\n",
      "Finished prepare_rna_edges().\n",
      "\n",
      "\n",
      "The function \"build_edges()\" is running...\n",
      "\n",
      "The function \"build_nodes()\" is running...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'iterrows'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer/transcriptomics.py\u001b[0m in \u001b[0;36mbuild_nodes\u001b[0;34m(edges)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;31m# build concept dict: {id:symbol}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0mconcept_dct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0medges\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m         \u001b[0;31m# node for subject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0mconcept_dct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subject_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'preflabel'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subject_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'iterrows'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# prepare data to graph schema\n",
    "csv_path = './transcriptomics/GSE64810_mlhd_DESeq2_diffexp_DESeq2_outlier_trimmed_adjust.txt'\n",
    "data = transcriptomics.read_data(csv_path, \"\\t\")\n",
    "clean_data = transcriptomics.clean_data(data)\n",
    "data_edges = transcriptomics.prepare_data_edges(clean_data)\n",
    "rna_network = transcriptomics.prepare_rna_edges(data_edges)\n",
    "\n",
    "# TODO:\n",
    "# This function still produces ENSEMBLE ID's even though the code should already return HGNC ones\n",
    "\n",
    "# build network with graph schema\n",
    "rna_edges = transcriptomics.build_edges(rna_network)\n",
    "rna_nodes, rna_dict = transcriptomics.build_nodes(rna_edges)\n",
    "rna_edges = transcriptomics.rework_edges(rna_edges, rna_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Transcriptomics network is returned as both digital object (`rna_edges`, `rna_nodes`) and CSV files at _**graph/**_ (`rna_edges_version.csv`, `rna_nodes_version.csv`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type edges: <class 'list'>\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rna_nodes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-39744771912b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# print type of objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'type edges:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrna_edges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'type nodes:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrna_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rna_nodes' is not defined"
     ]
    }
   ],
   "source": [
    "# print type of objects\n",
    "print('type edges:', type(rna_edges))\n",
    "print('type nodes:', type(rna_nodes))\n",
    "print()\n",
    "\n",
    "# print objects sizes\n",
    "print('len edges:', len(rna_edges))\n",
    "print('len nodes:', len(rna_nodes))\n",
    "print()\n",
    "\n",
    "# print object attribute\n",
    "print('attribute edges:', rna_edges[0].keys())\n",
    "print('attribute nodes:', rna_nodes[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REGULATION NETWORK\n",
    "#### import regulation\n",
    "\n",
    "We retrieved human TF gene expression regulation edges from several sources using the `regulation` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The function \"prepare_msigdb_data()\" is running...\n",
      "\n",
      "* Number of Transcription Factor Targets (TFT) gene sets: 615\n",
      "\n",
      "The MSigDB raw network is saved at: /home/karolis/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer/regulation/msigdb/out/tf_genelist_entrez_msigdb.json. Other reporting files are also saved at the same directory.\n",
      "\n",
      "\n",
      "Finished prepare_msigdb_data().\n",
      "\n",
      "\n",
      "The function \"load_tf_gene_edges()\" is running...\n",
      "\n",
      "Finished load_tf_gene_edges().\n",
      "\n",
      "\n",
      "The function \"get_gene_id_normalization_dictionaries()\" is running...\n",
      "\n",
      "* Querying BioThings to map gene symbols to HGNC and Entrez IDs...\n",
      "querying 1-1000...done.\n",
      "querying 1001-2000...done.\n",
      "querying 2001-3000...done.\n",
      "querying 3001-3071...done.\n",
      "Finished.\n",
      "50 input query terms found no hit:\n",
      "\t['CACBINDINGPROTEIN', 'CDPCR3', 'NKX25', 'CEBPGAMMA', 'E2F1DP1', 'CREBP1CJUN', 'TCF1P', 'CDPCR1', 'M\n",
      "Pass \"returnall=True\" to return complete lists of duplicate or missing query terms.\n",
      "\n",
      "Saving not found gene symbols at: /home/karolis/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer/regulation/not_found_symbols.list\n",
      "\n",
      "\n",
      "* Querying BioThings to map Entrez to HGNC IDs and gene symbols...\n",
      "querying 1-1000...done.\n",
      "querying 1001-2000...done.\n",
      "querying 2001-3000...done.\n",
      "querying 3001-4000...done.\n",
      "querying 4001-5000...done.\n",
      "querying 5001-6000...done.\n",
      "querying 6001-7000...done.\n",
      "querying 7001-8000...done.\n",
      "querying 8001-9000...done.\n",
      "querying 9001-10000...done.\n",
      "querying 10001-11000...done.\n",
      "querying 11001-12000...done.\n",
      "querying 12001-13000...done.\n",
      "querying 13001-14000...done.\n",
      "querying 14001-15000...done.\n",
      "querying 15001-16000...done.\n",
      "querying 16001-16632...done.\n",
      "Finished.\n",
      "148 input query terms found no hit:\n",
      "\t['221943', '256159', '23578', '51036', '439914', '100505695', '283650', '284083', '100616458', '3408\n",
      "Pass \"returnall=True\" to return complete lists of duplicate or missing query terms.\n",
      "\n",
      "Saving not found Entrez gene IDs at: /home/karolis/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer/regulation/not_found_entrez.list\n",
      "\n",
      "\n",
      "Finished get_gene_id_normalization_dictionaries().\n",
      "\n",
      "\n",
      "The function \"prepare_data_edges()\" is running...\n",
      "\n",
      "The tftargets edges are saved at: /home/karolis/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer/regulation/tftargets/tftargets_edges.csv\n",
      "\n",
      "\n",
      "The MSigDB edges are saved at: /home/karolis/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer/regulation/msigdb/msigdb_edges.csv\n",
      "\n",
      "\n",
      "Finished prepare_data_edges().\n",
      "\n",
      "\n",
      "The function \"prepare_regulation_edges()\" is running...\n",
      "\n",
      "Finished prepare_regulation_edges().\n",
      "\n",
      "\n",
      "The function \"build_edges()\" is running...\n",
      "\n",
      "* This is the size of the edges file data structure: (197267, 9)\n",
      "* These are the edges attributes: Index(['subject_id', 'object_id', 'property_id', 'property_label',\n",
      "       'property_description', 'property_uri', 'reference_uri',\n",
      "       'reference_supporting_text', 'reference_date'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "  subject_id  object_id property_id  property_label property_description  \\\n",
      "0  HGNC:8615  HGNC:8803  RO:0002434  interacts with                   NA   \n",
      "\n",
      "                                property_uri  \\\n",
      "0  http://purl.obolibrary.org/obo/RO_0002434   \n",
      "\n",
      "                                  reference_uri  \\\n",
      "0  https://www.ncbi.nlm.nih.gov/pubmed/17202159   \n",
      "\n",
      "                           reference_supporting_text reference_date  \n",
      "0  This edge comes from the TRED dataset in \"tfta...     2007-01-01  \n",
      "\n",
      "The regulation network edges are built and saved at: /home/karolis/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer/graph/regulation_edges_v2022-02-02.csv\n",
      "\n",
      "\n",
      "Finished build_edges().\n",
      "\n",
      "\n",
      "The function \"build_nodes()\" is running...\n",
      "\n",
      "* Total number of nodes: 16968\n",
      "\n",
      "* Trap genes without gene symbol, i.e. genes with discontinued entrez ID...\n",
      "* Number of concepts without gene symbol: 148\n",
      "* Check that all genes without gene symbol are identified by entrez ID...\n",
      "* Number of concepts without gene symbol by namespace:  NCBIGene    148\n",
      "Name: id, dtype: int64\n",
      "\n",
      "* Querying BioThings to map retired Entrez to gene symbols...\n",
      "querying 1-148...done.\n",
      "Finished.\n",
      "90 input query terms found no hit:\n",
      "\t['79907', '79911', '93333', '121301', '143902', '146856', '151720', '197379', '219392', '221943', '2\n",
      "Pass \"returnall=True\" to return complete lists of duplicate or missing query terms.\n",
      "\n",
      "* Querying BioThings to retrieve node attributes...\n",
      "querying 1-1000...done.\n",
      "querying 1001-2000...done.\n",
      "querying 2001-3000...done.\n",
      "querying 3001-4000...done.\n",
      "querying 4001-5000...done.\n",
      "querying 5001-6000...done.\n",
      "querying 6001-7000...done.\n",
      "querying 7001-8000...done.\n",
      "querying 8001-9000...done.\n",
      "querying 9001-10000...done.\n",
      "querying 10001-11000...done.\n",
      "querying 11001-12000...done.\n",
      "querying 12001-13000...done.\n",
      "querying 13001-14000...done.\n",
      "querying 14001-15000...done.\n",
      "querying 15001-16000...done.\n",
      "querying 16001-16839...done.\n",
      "Finished.\n",
      "50 input query terms found no hit:\n",
      "\t['CACBINDINGPROTEIN', 'NKX25', 'MEIS1AHOXA9', 'CEBPDELTA', 'AMEF2', 'MYCMAX', 'E2F1DP2', 'COREBINDIN\n",
      "Pass \"returnall=True\" to return complete lists of duplicate or missing query terms.\n",
      "\n",
      "* This is the size of the nodes file data structure: (16968, 6)\n",
      "* These are the nodes attributes: Index(['id', 'semantic_groups', 'preflabel', 'name', 'synonyms',\n",
      "       'description'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "          id semantic_groups preflabel          name    synonyms  \\\n",
      "0  HGNC:8615            GENE      PAX1  paired box 1  HUP48|OFC2   \n",
      "\n",
      "                                         description  \n",
      "0  This gene is a member of the paired box (PAX) ...  \n",
      "\n",
      "The regulation network nodes are built and saved at: /home/karolis/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer/graph/regulation_nodes_v2022-02-02.csv\n",
      "\n",
      "\n",
      "Finished build_nodes().\n",
      "\n",
      "CPU times: user 1min 4s, sys: 218 ms, total: 1min 4s\n",
      "Wall time: 2min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# prepare msigdb data\n",
    "gmt_path = './regulation/msigdb/data/c3.tft.v6.1.entrez.gmt'\n",
    "regulation.prepare_msigdb_data(gmt_path)\n",
    "\n",
    "# prepare individual networks\n",
    "data = regulation.load_tf_gene_edges()\n",
    "dicts = regulation.get_gene_id_normalization_dictionaries(data)\n",
    "data_edges = regulation.prepare_data_edges(data, dicts)\n",
    "\n",
    "# prepare regulation network\n",
    "reg_network = regulation.prepare_regulation_edges(data_edges)\n",
    "\n",
    "# build network with graph schema\n",
    "reg_edges = regulation.build_edges(reg_network)\n",
    "reg_nodes = regulation.build_nodes(reg_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Regulation network is returned as both digital object (`reg_edges`, `reg_nodes`) and CSV files at _**graph/**_ (`regulation_edges_version.csv`, `regulation_nodes_version.csv`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type edges: <class 'list'>\n",
      "type nodes: <class 'list'>\n",
      "\n",
      "len edges: 197267\n",
      "len nodes: 16968\n",
      "\n",
      "attribute edges: dict_keys(['subject_id', 'object_id', 'property_id', 'property_label', 'property_description', 'property_uri', 'reference_uri', 'reference_supporting_text', 'reference_date'])\n",
      "attribute nodes: dict_keys(['id', 'semantic_groups', 'preflabel', 'name', 'synonyms', 'description'])\n"
     ]
    }
   ],
   "source": [
    "# print type of objects\n",
    "print('type edges:', type(reg_edges))\n",
    "print('type nodes:', type(reg_nodes))\n",
    "print()\n",
    "\n",
    "# print objects sizes\n",
    "print('len edges:', len(reg_edges))\n",
    "print('len nodes:', len(reg_nodes))\n",
    "print()\n",
    "\n",
    "# print object attribute\n",
    "print('attribute edges:', reg_edges[0].keys())\n",
    "print('attribute nodes:', reg_nodes[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CURATED NETWORK\n",
    "#### import curation\n",
    "\n",
    "We retrieved and prepared curated edges using the `curation` module. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "curation_edges = pd.read_csv(\"curation/data/HD/Empty_edges.csv\")\n",
    "curation_nodes = pd.read_csv(\"curation/data/HD/Empty_nodes.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "%%time\n",
    "# graph v3.2\n",
    "# read network from drive and concat all curated statements\n",
    "curation_edges, curation_nodes = curation.read_network(version='v20180118')\n",
    "\n",
    "# prepare data edges and nodes\n",
    "data_edges = curation.prepare_data_edges(curation_edges)\n",
    "data_nodes = curation.prepare_data_nodes(curation_nodes)\n",
    "\n",
    "# prepare curated edges and nodes\n",
    "curated_network = curation.prepare_curated_edges(data_edges)\n",
    "curated_concepts = curation.prepare_curated_nodes(data_nodes)\n",
    "\n",
    "\n",
    "# build edges and nodes files\n",
    "curation_edges = curation.build_edges(curated_network)\n",
    "curation_nodes = curation.build_nodes(curated_concepts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Curated network is returned as both digital object (`curation_edges`, `curation_nodes`) and CSV files at _**graph/**_ (`curated_graph_edges_version.csv`, `curated_graph_nodes_version.csv`)\n",
    "- The original curated network, i.e. without graph data model normalization, is saved as CSV files at _**curation/**_ (`curated_edges_version.csv`, `curated_nodes_version.csv`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print type of objects\n",
    "print('type edges:', type(curation_edges))\n",
    "print('type nodes:', type(curation_nodes))\n",
    "print()\n",
    "\n",
    "# print objects sizes\n",
    "print('len edges:', len(curation_edges))\n",
    "print('len nodes:', len(curation_nodes))\n",
    "print()\n",
    "\n",
    "# print object attribute\n",
    "print('attribute edges:', curation_edges[0].keys())\n",
    "print('attribute nodes:', curation_nodes[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MONARCH NETWORK\n",
    "#### import monarch\n",
    "We retrieved edges from Monarch using the `monarch` module.\n",
    "\n",
    "Tasks:\n",
    "\n",
    "- From 8 seed nodes we retrieved 1st shell nodes\n",
    "- From all seed and 1st shell nodes we retrieved ortho-phenotypes\n",
    "- We retrieved extra edges among all of them, i.e. extra connectivity between: seed, 1st shell, ortholog-phenotype nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The function \"get_neighbours_list()\" is running. Its runtime may take some minutes. If you interrupt the process, you will lose all the nodes retrieved and you should start over the execution of this function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:16<00:00,  4.12s/it]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished get_neighbours_list().\n",
      "\n",
      "1034\n",
      "\n",
      "The function \"get_orthopheno_list()\" is running. Its runtime may take some hours. If you interrupt the process, you will lose all the nodes retrieved and you should start over the execution of this function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:09<00:00,  2.27s/it]\n",
      "100%|██████████| 16/16 [00:21<00:00,  1.32s/it]\n",
      "  0%|          | 0/1034 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished get_orthopheno_list().\n",
      "\n",
      "219\n",
      "\n",
      "The function \"get_orthopheno_list()\" is running. Its runtime may take some hours. If you interrupt the process, you will lose all the nodes retrieved and you should start over the execution of this function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 809/1034 [29:48<10:32,  2.81s/it]  "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# prepare data to graph schema\n",
    "# seed nodes\n",
    "seedList = [ \n",
    "    'MONDO:0007739', # HD\n",
    "    'HGNC:4851', # Htt\n",
    "    'HGNC:182293', # Rhes\n",
    "    'REACT:R-HSA-917937' #Iron uptake pathway\n",
    "] \n",
    "\n",
    "# get first shell of neighbours\n",
    "neighboursList = monarch.get_neighbours_list(seedList)\n",
    "print(len(neighboursList))\n",
    "\n",
    "# introduce animal model ortho-phenotypes for seed and 1st shell neighbors\n",
    "## For seed nodes:\n",
    "seed_orthophenoList = monarch.get_orthopheno_list(seedList)\n",
    "print(len(seed_orthophenoList))\n",
    "## For 1st shell nodes:\n",
    "neighbours_orthophenoList = monarch.get_orthopheno_list(neighboursList)\n",
    "print(len(neighbours_orthophenoList))\n",
    "\n",
    "# network nodes: seed + 1shell + ortholog-phentoype\n",
    "geneList = sum([seedList,\n",
    "                neighboursList,\n",
    "                seed_orthophenoList,\n",
    "                neighbours_orthophenoList\n",
    "               ], \n",
    "               [])\n",
    "print('genelist: ',len(geneList))\n",
    "\n",
    "# get Monarch network\n",
    "monarch_network = monarch.extract_edges(geneList)\n",
    "print('network: ',len(monarch_network))\n",
    "\n",
    "# save edges\n",
    "monarch.print_network(monarch_network, 'monarch_connections')\n",
    "\n",
    "# build network with graph schema \n",
    "monarch_edges = monarch.build_edges(monarch_network)\n",
    "monarch_nodes = monarch.build_nodes(monarch_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "monarch.print_network(monarch_network, 'monarch_connections')\n",
    "\n",
    "# build network with graph schema \n",
    "monarch_edges = monarch.build_edges(monarch_network)\n",
    "monarch_nodes = monarch.build_nodes(monarch_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print type of objects\n",
    "print('type edges:', type(monarch_edges))\n",
    "print('type nodes:', type(monarch_nodes))\n",
    "print()\n",
    "\n",
    "# print objects sizes\n",
    "print('len edges:', len(monarch_edges))\n",
    "print('len nodes:', len(monarch_nodes))\n",
    "print()\n",
    "\n",
    "# print object attribute\n",
    "print('attribute edges:', monarch_edges[0].keys())\n",
    "print('attribute nodes:', monarch_nodes[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "%%time\n",
    "# prepare data to graph schema\n",
    "# seed nodes\n",
    "seedList = [ \n",
    "    'MONDO:0007739', # HD\n",
    "    'HGNC:4851', # Htt\n",
    "    'HGNC:182293', # Rhes\n",
    "] \n",
    "\n",
    "# get first shell of neighbours\n",
    "neighboursList = monarch.get_neighbours_list(seedList)\n",
    "print(len(neighboursList))\n",
    "\n",
    "# introduce animal model ortho-phenotypes for seed and 1st shell neighbors\n",
    "## For seed nodes:\n",
    "seed_orthophenoList = monarch.get_orthopheno_list(seedList)\n",
    "print(len(seed_orthophenoList))\n",
    "## For 1st shell nodes:\n",
    "neighbours_orthophenoList = monarch.get_orthopheno_list(neighboursList)\n",
    "print(len(neighbours_orthophenoList))\n",
    "\n",
    "# network nodes: seed + 1shell + ortholog-phentoype\n",
    "geneList = sum([seedList,\n",
    "                neighboursList,\n",
    "                #seed_orthophenoList,\n",
    "                #neighbours_orthophenoList\n",
    "               ], \n",
    "               [])\n",
    "print('genelist: ',len(geneList))\n",
    "\n",
    "# get Monarch network\n",
    "monarch_network = monarch.extract_edges(geneList)\n",
    "print('network: ',len(monarch_network))\n",
    "\n",
    "# save edges\n",
    "monarch.print_network(monarch_network, 'monarch_connections')\n",
    "\n",
    "# build network with graph schema \n",
    "monarch_edges = monarch.build_edges(monarch_network)\n",
    "monarch_nodes = monarch.build_nodes(monarch_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "monarch_network = monarch.read_connections(\"monarch_connections_v2020-11-15.csv\")\n",
    "monarch_edges = monarch.build_edges(monarch_network)\n",
    "monarch_nodes = monarch.build_nodes(monarch_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "monarch_edges = monarch.build_edges(monarch_network)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "monarch_nodes = monarch.build_nodes(monarch_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print type of objects\n",
    "print('type edges:', type(monarch_edges))\n",
    "print('type nodes:', type(monarch_nodes))\n",
    "print()\n",
    "\n",
    "# print objects sizes\n",
    "print('len edges:', len(monarch_edges))\n",
    "print('len nodes:', len(monarch_nodes))\n",
    "print()\n",
    "\n",
    "# print object attribute\n",
    "print('attribute edges:', monarch_edges[0].keys())\n",
    "print('attribute nodes:', monarch_nodes[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Monarch network is returned as both digital object (`monarch_edges`, `monarch_nodes`) and CSV files at _**monarch/**_ (`monarch_edges_version.csv`, `monarch_nodes_version.csv`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph library\n",
    "### Create the review knowledge graph\n",
    "#### import graph\n",
    "\n",
    "Tasks:\n",
    "\n",
    "* Load Networks and calculate graph nodes\n",
    "* Retrieve extra connectivity for the graph from Monarch\n",
    "* Build the review graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curation_edges = pd.read_csv(\"curation/data/HD/Empty_edges.csv\")\n",
    "curation_nodes = pd.read_csv(\"curation/data/HD/Empty_nodes.csv\")\n",
    "curation_nodes = curation_nodes.astype('object')\n",
    "curation_nodes['name'] = [\"NaN\", \"NaN\"]\n",
    "curation_edges = curation_edges.to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# obtain variables:\n",
    "#curation_edges = pd.read_csv(\"curation/data/HD/Empty_edges.csv\")\n",
    "#curation_nodes = pd.read_csv(\"curation/data/HD/Empty_nodes.csv\")\n",
    "\n",
    "monarch_network = monarch.read_connections(\"monarch_connections_v2020-12-12.csv\")\n",
    "monarch_edges = monarch.build_edges(monarch_network)\n",
    "monarch_nodes = monarch.build_nodes(monarch_network)\n",
    "\n",
    "#monarch_network_graph = monarch.read_connections(\"monarch_connections_graph_v2020-12-02.csv\")\n",
    "#monarch_graph_edges = monarch.build_edges(monarch_network_graph)\n",
    "#monarch_graph_nodes = monarch.build_nodes(monarch_network_graph)\n",
    "\n",
    "csv_path = './transcriptomics/GSE64810_mlhd_DESeq2_diffexp_DESeq2_outlier_trimmed_adjust.txt'\n",
    "data = transcriptomics.read_data(csv_path)\n",
    "clean_data = transcriptomics.clean_data(data)\n",
    "data_edges = transcriptomics.prepare_data_edges(clean_data)\n",
    "rna_network = transcriptomics.prepare_rna_edges(data_edges)\n",
    "\n",
    "# build network with graph schema\n",
    "rna_edges = transcriptomics.build_edges(rna_network)\n",
    "rna_nodes, rna_edges = transcriptomics.build_nodes(rna_network)\n",
    "\n",
    "gmt_path = './regulation/msigdb/data/c3.tft.v6.1.entrez.gmt'\n",
    "regulation.prepare_msigdb_data(gmt_path)\n",
    "\n",
    "# prepare individual networks\n",
    "data = regulation.load_tf_gene_edges()\n",
    "dicts = regulation.get_gene_id_normalization_dictionaries(data)\n",
    "data_edges = regulation.prepare_data_edges(data, dicts)\n",
    "\n",
    "# prepare regulation network\n",
    "reg_network = regulation.prepare_regulation_edges(data_edges)\n",
    "\n",
    "# build network with graph schema\n",
    "reg_edges = regulation.build_edges(reg_network)\n",
    "reg_nodes = regulation.build_nodes(reg_network)\n",
    "\n",
    "#graph_nodes_list, reg_graph_edges = graph.graph_nodes(\n",
    "#    curation=curation_edges,\n",
    "#    monarch=monarch_edges,\n",
    "#    transcriptomics=rna_edges,\n",
    "#    regulation=reg_edges\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_network.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(rna_edges).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# load networks and calculate graph nodes\n",
    "graph_nodes_list, reg_graph_edges = graph.graph_nodes(\n",
    "    curation=curation_edges,\n",
    "    monarch=monarch_edges,\n",
    "    transcriptomics=rna_edges,\n",
    "    regulation=reg_edges\n",
    ")\n",
    "\n",
    "# Monarch graph connectivity\n",
    "## get Monarch edges\n",
    "monarch_network_graph = monarch.extract_edges(graph_nodes_list)\n",
    "print('network: ',len(monarch_network_graph))\n",
    "\n",
    "## save Monarch network\n",
    "monarch.print_network(monarch_network_graph, 'monarch_connections_graph')\n",
    "\n",
    "## build Monarch network with graph schema\n",
    "monarch_graph_edges = monarch.build_edges(monarch_network_graph)\n",
    "monarch_graph_nodes = monarch.build_nodes(monarch_network_graph)\n",
    "\n",
    "# build review graph\n",
    "edges = graph.build_edges(\n",
    "    curation=curation_edges,\n",
    "    monarch=monarch_graph_edges,\n",
    "    transcriptomics=rna_edges,\n",
    "    regulation=reg_graph_edges\n",
    ")\n",
    "nodes = graph.build_nodes(\n",
    "    statements=edges,\n",
    "    curation=curation_nodes,\n",
    "    monarch=monarch_graph_nodes,\n",
    "    transcriptomics=rna_nodes,\n",
    "    regulation=reg_nodes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_df = pd.DataFrame(curation_edges)\n",
    "monarch_df = pd.DataFrame(monarch_edges)\n",
    "rna = pd.DataFrame(rna_edges)\n",
    "tf = pd.DataFrame(reg_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monarch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statements = pd.concat([curated_df, monarch_df, rna], ignore_index=True, join=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge1 = pd.merge(statements, tf, how='inner', left_on='subject_id', right_on='subject_id',\n",
    "                      suffixes=('_graph', '_tf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge1_clean = (merge1\n",
    "    [['subject_id', 'property_id_tf', 'object_id_tf', 'reference_uri_tf',\n",
    "      'reference_supporting_text_tf', 'reference_date_tf', 'property_label_tf',\n",
    "      'property_description_tf', 'property_uri_tf']]\n",
    "        .rename(columns={\n",
    "        'property_id_tf': 'property_id',\n",
    "        'object_id_tf': 'object_id',\n",
    "        'reference_uri_tf': 'reference_uri',\n",
    "        'reference_supporting_text_tf': 'reference_supporting_text',\n",
    "        'reference_date_tf': 'reference_date',\n",
    "        'property_label_tf': 'property_label',\n",
    "        'property_description_tf': 'property_description',\n",
    "        'property_uri_tf': 'property_uri'\n",
    "    })\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fix curation data:\n",
    "curation_nodes = curation_nodes.astype('object')\n",
    "#curation_nodes.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "curation_nodes = curation_nodes.astype('object')\n",
    "curation_nodes['name'] = [\"NaN\", \"NaN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "curation_nodes.loc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# construct df's\n",
    "edges = graph.build_edges(\n",
    "    curation=curation_edges,\n",
    "    monarch=monarch_edges,\n",
    "    transcriptomics=rna_edges,\n",
    "    regulation=reg_edges\n",
    ")\n",
    "nodes = graph.build_nodes(\n",
    "    statements=edges,\n",
    "    curation=curation_nodes,\n",
    "    monarch=monarch_nodes,\n",
    "    transcriptomics=rna_nodes,\n",
    "    regulation=reg_nodes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nodes = pd.read_csv(\"/home/karolis/Structured review/bioknowledge-reviewer/bioknowledge_reviewer/graph/graph_nodes_v2020-11-20.csv\")\n",
    "edges = pd.read_csv(\"/home/karolis/Structured review/bioknowledge-reviewer/bioknowledge_reviewer/graph/graph_edges_v2020-11-20.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Regulation edges _merged_ with the graph is returned as both digital object (`reg_graph_edges`) and CSV file at _**graph/**_ (`regulation_graph_edges_version.csv`)\n",
    "- Monarch network is returned as both digital object (`monarch_graph_edges`, `monarch_graph_nodes`) and CSV files at _**monarch/**_ (`monarch_edges_version.csv`, `monarch_nodes_version.csv`) overwritten the previous one.\n",
    "- Review knowledge graph is returned as both digital object (`edges`, `nodes`) and CSV files at _**graph/**_ (`graph_edges_version.csv`, `graph_nodes_version.csv`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neo4jlib library\n",
    "### Import the graph into Neo4j graph database\n",
    "#### import neo4jlib\n",
    "\n",
    "Tasks:\n",
    "\n",
    "- Create Neo4j server instance\n",
    "- Import review graph into the Neo4j graph database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/karolis/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_df = pd.read_csv(\"~/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer/graph/graph_edges_v2021-04-12.csv\")\n",
    "nodes_df = pd.read_csv(\"~/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer/graph/graph_nodes_v2021-04-12.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a Neo4j community v3.5.6 server instance...\n",
      "Configuration adjusted!\n",
      "Neo4j v3.5.6 is running.\n",
      "The name of the neo4j directory is neo4j-community-3.5.6\n",
      "statements:  593223\n",
      "concepts:  19721\n",
      "\n",
      "File './neo4j-community-3.5.6/import/ngly1/ngly1_statements.csv' saved.\n",
      "\n",
      "File './neo4j-community-3.5.6/import/ngly1/ngly1_concepts.csv' saved.\n",
      "\n",
      "The function \"do_import()\" is running...\n",
      "\n",
      "The graph is imported into the server. Neo4j is running.You can start exploring and querying for hypothesis. If you change ports or authentication in the Neo4j configuration file, the hypothesis-generation modules performance, hypothesis.py and summary.py, will be affected.\n",
      "\n",
      "CPU times: user 4.39 s, sys: 193 ms, total: 4.58 s\n",
      "Wall time: 17.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create a Neo4j server instance\n",
    "neo4j_dir = neo4jlib.create_neo4j_instance('3.5.6')\n",
    "print('The name of the neo4j directory is {}'.format(neo4j_dir))\n",
    "\n",
    "# import to graph database\n",
    "## prepare the graph to neo4j format\n",
    "#edges_df = utils.get_dataframe(edges)\n",
    "#nodes_df = utils.get_dataframe(nodes)\n",
    "statements = neo4jlib.get_statements(edges_df)\n",
    "concepts = neo4jlib.get_concepts(nodes_df)\n",
    "print('statements: ', len(statements))\n",
    "print('concepts: ',len(concepts))\n",
    "\n",
    "## save files into neo4j import dir\n",
    "neo4j_path = './{}'.format(neo4j_dir)\n",
    "neo4jlib.save_neo4j_files(statements, neo4j_path, file_type = 'statements')\n",
    "neo4jlib.save_neo4j_files(concepts, neo4j_path, file_type = 'concepts')\n",
    "\n",
    "## import graph into neo4j database\n",
    "neo4jlib.do_import(neo4j_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del edges_df\n",
    "del nodes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print type of objects\n",
    "print('type edges:', type(statements))\n",
    "print('type nodes:', type(concepts))\n",
    "print()\n",
    "\n",
    "# print objects sizes\n",
    "print('len edges:', len(statements))\n",
    "print('len nodes:', len(concepts))\n",
    "print()\n",
    "\n",
    "# print object attribute\n",
    "print('attribute edges:', statements.columns)\n",
    "print('attribute nodes:', concepts.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hypothesis-generation library\n",
    "### Query the graph for mechanistic explanation, then summarize the extracted paths\n",
    "#### import hypothesis, summary\n",
    "\n",
    "\n",
    "Tasks:\n",
    "\n",
    "* Retrieve orthopheno paths with the `query` method.\n",
    "* Retrieve orthopheno paths using relaxing node degree parameters with the `query` method.\n",
    "* Retrieve orthopheno paths from a more open query topology with the `open_query` method.\n",
    "* Get hypothesis summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ortopheno query with general nodes/relations removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import sys,os\n",
    "import json\n",
    "import yaml\n",
    "import datetime\n",
    "import neo4j.exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_path( path ):\n",
    "    \"\"\"\n",
    "    This function parses neo4j results.\n",
    "    :param path: neo4j path object\n",
    "    :return: parsed path dictionary\n",
    "    \"\"\"\n",
    "\n",
    "    out = {}\n",
    "    out['Nodes'] = []\n",
    "    for node in path['path'].nodes:\n",
    "        n = {}\n",
    "        n['idx'] = node.id\n",
    "        n['label'] = list(node.labels)[0]\n",
    "        n['id'] = node.get('id')\n",
    "        n['preflabel'] = node.get('preflabel')\n",
    "        n['name'] = node.get('name')\n",
    "        n['description'] = node.get('description')\n",
    "        out['Nodes'].append(n)\n",
    "    out['Edges'] = []\n",
    "    for edge in path['path'].relationships:\n",
    "        e = {}\n",
    "        e['idx'] = edge.id\n",
    "        e['start_node'] = edge.start_node.id\n",
    "        e['end_node'] = edge.end_node.id\n",
    "        e['type'] = edge.type\n",
    "        e['preflabel'] = edge.get('property_label')\n",
    "        e['references'] = edge.get('reference_uri')\n",
    "        out['Edges'].append(e)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node(source, target, port='7687'):\n",
    "    \"\"\"\n",
    "    This function checks if a node exists within the graph\n",
    "    \"\"\"\n",
    "    try:\n",
    "        driver = GraphDatabase.driver(\"bolt://localhost:{}\".format(port), auth=(\"neo4j\", \"ngly1\"))\n",
    "    except neo4j.exceptions.ServiceUnavailable:\n",
    "        raise\n",
    "    outputAll = list()\n",
    "    with driver.session() as session:\n",
    "        query = \"\"\"MATCH (source { id: '\"\"\" + source + \"\"\"' }), (target { id: '\"\"\" + target +  \"\"\"' }), p = allShortestPaths((source)-[*..15]-(target)) RETURN p\"\"\"\n",
    "        result = session.run(query)\n",
    "        print(result)\n",
    "        x = []\n",
    "        for record in result:\n",
    "            #path_dct = parse_path(record)\n",
    "            x.append(record)\n",
    "        print(x)\n",
    "        return x, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x, result = get_node('HGNC:4851', 'HGNC:18229')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.consume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_shortest_paths(source, target, max_length=4, port='7687'):\n",
    "    \"\"\"\n",
    "    This function gets the shortest paths between source and\n",
    "    target. max_length determines the maximum path size allowed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        driver = GraphDatabase.driver(\"bolt://localhost:{}\".format(port), auth=(\"neo4j\", \"ngly1\"))\n",
    "    except neo4j.exceptions.ServiceUnavailable:\n",
    "        raise\n",
    "    outputAll = list()\n",
    "    with driver.session() as session:\n",
    "        print(\"kaas\")\n",
    "        query = \"\"\"MATCH (source { id: '\"\"\" + source + \"\"\"' }), (target { id: '\"\"\" + target +  \"\"\"' }), p = shortestPath((source)-[*..15]-(target)) RETURN p\"\"\"\n",
    "        result = session.run(query)\n",
    "        print(result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seed = list([\n",
    "        'HGNC:4851',  # Htt human gene\n",
    "        'HGNC:18229'  # Rhes human gene\n",
    "])\n",
    "result = query_shortest_paths(seed[0], seed[1], max_length=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = result.consume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# get orthopheno paths\n",
    "seed = list([\n",
    "        'HGNC:4851',  # Htt human gene\n",
    "        'HGNC:18229'  # Rhes human gene\n",
    "])\n",
    "hypothesis.query(seed,queryname='Htt_Rhes',port='7687') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# get orthopheno paths relaxing pathway and phenotype node degrees\n",
    "seed = list([\n",
    "        'HGNC:4851',  # NGLY1 human gene\n",
    "        'HGNC:18229'  # AQP1 human gene\n",
    "])\n",
    "hypothesis.query(seed, queryname='Htt_Rhes', pwdegree='1000', phdegree='1000', port='7687')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# get orthopheno paths from a more open query topogology\n",
    "seed = list([\n",
    "        'HGNC:4851',  # NGLY1 human gene\n",
    "        'HGNC:18229'  # AQP1 human gene\n",
    "])\n",
    "hypothesis.open_query(seed,queryname='Htt_Rhes',port='7687')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "seed = list([\n",
    "        'HGNC:4851',  # NGLY1 human gene\n",
    "        'HGNC:18229'  # AQP1 human gene\n",
    "])\n",
    "r = hypothesis.shortest_paths(seed[0], seed[1], max_length=50, port='7687')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# get summary\n",
    "data = summary.path_load('./hypothesis/query_ngly1_aqp1_pwdl1000_phdl1000_paths_v2020-09-14.json')\n",
    "\n",
    "# parse data for summarization\n",
    "data_parsed = list()\n",
    "for query in data:\n",
    "    query_parsed = summary.query_parser(query)\n",
    "    data_parsed.append(query_parsed)\n",
    "summary.metapaths(data_parsed)\n",
    "summary.nodes(data_parsed)\n",
    "summary.node_types(data_parsed)\n",
    "summary.edges(data_parsed)\n",
    "summary.edge_types(data_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

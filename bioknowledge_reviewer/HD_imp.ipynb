{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @name graph_v3.2_v20190616\n",
    "# @description notebook to build the NGLY1 Deficiency review knowledge graph v3.2\n",
    "# @author NÃºria Queralt Rosinach\n",
    "# @date 16 June 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "This is the notebook for the creation of the first review network and derived hypotheses. \n",
    "\n",
    "* Using intermediary variables from workflow objects. In this workflow variables are directly used for the next step. \n",
    "\n",
    "\n",
    "* Review network: From Monarch knowledge graph, we built a network seeded by 8 nodes, retrieving their explicit relationships and all the relationships among all these nodes. Seed nodes:\n",
    "\n",
    "    - 'MONDO:0007739' HD\n",
    "    - 'HGNC:4851' Htt\n",
    "    - 'CHEBI:18248' Iron (not working)\n",
    "    - 'HGNC:18229' Rhes (RASD2)\n",
    "    \n",
    "Possible seed nodes:\n",
    "https://monarchinitiative.org/search/Iron\n",
    "* Connecting paths: query templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transcriptomics, regulation, curation, monarch, graph, neo4jlib, hypothesis, summary, utils\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#onarch.get_connections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nodes, edges = monarch.get_neighbours([\"HGNC:18229\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#nodes2, edges2 = monarch.get_neighbours(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edges library\n",
    "### Review edges to integrate into the knowledge graph and prepare them as individual networks\n",
    "\n",
    "#### TRANSCRIPTOMICS NETWORK\n",
    "#### import transcriptomics\n",
    "We retrieved edges from RNA-seq transcriptomics profiles using the `transcriptomics` module:\n",
    "\n",
    "    - Experimental data sets: from Chow et al. paper [pmid:29346549] (NGLY1 deficiency model on fruit fly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The function \"read_data()\" is running...\n",
      "\n",
      "* This is the size of the raw expression data structure: (28087, 10)\n",
      "* These are the expression attributes: Index(['Unnamed: 0', 'symbol', 'baseMean', 'HD.mean', 'Control.mean',\n",
      "       'log2FoldChange', 'lfcSE', 'stat', 'pvalue', 'padj'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "           Unnamed: 0 symbol  baseMean    HD.mean  Control.mean  \\\n",
      "0  ENSG00000069011.10  PITX1  5.645675  18.684286      0.323793   \n",
      "\n",
      "   log2FoldChange     lfcSE      stat        pvalue          padj  \n",
      "0        4.769658  0.366367  13.01879  9.567529e-39  2.687232e-34  \n",
      "\n",
      "The raw data is saved at: /home/karolis/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer/transcriptomics/HD/data/GSE64810_mlhd_DESeq2_diffexp_DESeq2_outlier_trimmed_adjust.csv\n",
      "\n",
      "\n",
      "Finished read_data().\n",
      "\n",
      "CPU times: user 35.8 ms, sys: 7.35 ms, total: 43.2 ms\n",
      "Wall time: 62 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# prepare data to graph schema\n",
    "csv_path = './transcriptomics/GSE64810_mlhd_DESeq2_diffexp_DESeq2_outlier_trimmed_adjust.txt'\n",
    "data = transcriptomics.read_data(csv_path, \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The function \"read_data()\" is running...\n",
      "\n",
      "* This is the size of the raw expression data structure: (28087, 10)\n",
      "* These are the expression attributes: Index(['Unnamed: 0', 'symbol', 'baseMean', 'HD.mean', 'Control.mean',\n",
      "       'log2FoldChange', 'lfcSE', 'stat', 'pvalue', 'padj'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "           Unnamed: 0 symbol  baseMean    HD.mean  Control.mean  \\\n",
      "0  ENSG00000069011.10  PITX1  5.645675  18.684286      0.323793   \n",
      "\n",
      "   log2FoldChange     lfcSE      stat        pvalue          padj  \n",
      "0        4.769658  0.366367  13.01879  9.567529e-39  2.687232e-34  \n",
      "\n",
      "The raw data is saved at: /home/karolis/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer/transcriptomics/HD/data/GSE64810_mlhd_DESeq2_diffexp_DESeq2_outlier_trimmed_adjust.csv\n",
      "\n",
      "\n",
      "Finished read_data().\n",
      "\n",
      "\n",
      "The function \"clean_data()\" is running. Keeping only data with FC > 1.5 and FDR < 5% ...\n",
      "\n",
      "* This is the size of the clean expression data structure: (3209, 6)\n",
      "* These are the clean expression attributes: Index(['EnsembleID', 'symbol', 'log2FoldChange', 'pvalue', 'padj',\n",
      "       'Regulation'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "           EnsembleID symbol  log2FoldChange        pvalue          padj  \\\n",
      "0  ENSG00000069011.10  PITX1        4.769658  9.567529e-39  2.687232e-34   \n",
      "\n",
      "    Regulation  \n",
      "0  Upregulated  \n",
      "\n",
      "The clean data is saved at: /home/karolis/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer/transcriptomics/HD/out/Transcriptome_human_BA9.csv\n",
      "\n",
      "\n",
      "Finished clean_data().\n",
      "\n",
      "\n",
      "The function \"prepare_data_edges()\" is running...\n",
      "\n",
      "* This is the size of the expression data structure: (3209, 13)\n",
      "* These are the expression attributes: Index(['ensemble_id', 'symbol', 'log2FoldChange', 'pvalue', 'padj',\n",
      "       'regulation', 'source', 'subject_id', 'subject_label', 'property_id',\n",
      "       'property_label', 'reference_id', 'object_id'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "          ensemble_id symbol  log2FoldChange        pvalue          padj  \\\n",
      "0  ENSG00000069011.10  PITX1        4.769658  9.567529e-39  2.687232e-34   \n",
      "\n",
      "    regulation source               subject_id subject_label property_id  \\\n",
      "0  Upregulated   Chow  ensembl:ENSG00000197386           HTT  RO:0002434   \n",
      "\n",
      "   property_label   reference_id                object_id  \n",
      "0  interacts with  PMID:26636579  ensembl:ENSG00000069011  \n",
      "\n",
      "The HD BA9 transcriptomics expression edges are saved at: /home/karolis/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer/transcriptomics/HD/out/Transcriptome_human_BA9_edges.csv\n",
      "\n",
      "\n",
      "Finished prepare_data_edges().\n",
      "\n",
      "\n",
      "The function \"prepare_rna_edges()\" is running...\n",
      "\n",
      "* This is the size of the edges data structure: (3209, 12)\n",
      "* These are the edges attributes: Index(['subject_id', 'subject_label', 'property_id', 'property_label',\n",
      "       'object_id', 'object_label', 'log2FoldChange', 'pvalue', 'fdr',\n",
      "       'regulation', 'source', 'reference_id'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "                subject_id subject_label property_id  property_label  \\\n",
      "0  ensembl:ENSG00000197386           HTT  RO:0002434  interacts with   \n",
      "\n",
      "                 object_id object_label  log2FoldChange        pvalue  \\\n",
      "0  ensembl:ENSG00000069011        PITX1        4.769658  9.567529e-39   \n",
      "\n",
      "            fdr   regulation source   reference_id  \n",
      "0  2.687232e-34  Upregulated   Chow  PMID:26636579  \n",
      "\n",
      "This data object is not saved.\n",
      "\n",
      "\n",
      "Finished prepare_rna_edges().\n",
      "\n",
      "\n",
      "The function \"build_edges()\" is running...\n",
      "\n",
      "The function \"build_nodes()\" is running...\n",
      "* Total number of nodes: 3210\n",
      "querying 1-1000...done.\n",
      "querying 1001-2000...done.\n",
      "querying 2001-3000...done.\n",
      "querying 3001-3210...done.\n",
      "Finished.\n",
      "178 input query terms found no hit:\n",
      "\t['ENSG00000200127', 'ENSG00000183748', 'ENSG00000140181', 'ENSG00000261589', 'ENSG00000034063', 'ENS\n",
      "Pass \"returnall=True\" to return complete lists of duplicate or missing query terms.\n",
      "178 nodes without available information\n",
      "These nodes have retained their original ID. First three nodes are:\n",
      "['ENSG00000200127', 'ENSG00000183748', 'ENSG00000140181']\n",
      "789 nodes do not have a HGNC id, retained original ID\n",
      "\n",
      "* This is the size of the nodes file data structure: (3210, 6)\n",
      "* These are the nodes attributes: Index(['id', 'semantic_groups', 'preflabel', 'name', 'synonyms',\n",
      "       'description'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "          id semantic_groups preflabel        name        synonyms  \\\n",
      "0  HGNC:4851            GENE       HTT  huntingtin  HD|IT15|LOMARS   \n",
      "\n",
      "                                         description  \n",
      "0  Huntingtin is a disease gene linked to Hunting...  \n",
      "\n",
      "The transcriptomics network nodes are built and saved at: /home/karolis/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer/graph/rna_nodes_v2022-04-06.csv\n",
      "\n",
      "\n",
      "Finished build_nodes().\n",
      "\n",
      "\n",
      "* This is the size of the edges file data structure: (3209, 9)\n",
      "* These are the edges attributes: Index(['subject_id', 'object_id', 'property_id', 'property_label',\n",
      "       'property_description', 'property_uri', 'reference_uri',\n",
      "       'reference_supporting_text', 'reference_date'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "  subject_id  object_id property_id  property_label property_description  \\\n",
      "0  HGNC:4851  HGNC:9004  RO:0002434  interacts with                   NA   \n",
      "\n",
      "                                property_uri  \\\n",
      "0  http://purl.obolibrary.org/obo/RO_0002434   \n",
      "\n",
      "                                  reference_uri  \\\n",
      "0  https://www.ncbi.nlm.nih.gov/pubmed/26636579   \n",
      "\n",
      "                           reference_supporting_text reference_date  \n",
      "0  Here we present a genome-wide analysis of mRNA...     2015-11-04  \n",
      "\n",
      "The transcriptomics network edges are built and saved at: /home/karolis/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer/graph/rna_edges_v2022-04-06.csv\n",
      "\n",
      "\n",
      "Finished build_edges().\n",
      "\n",
      "CPU times: user 1.26 s, sys: 0 ns, total: 1.26 s\n",
      "Wall time: 11.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# prepare data to graph schema\n",
    "csv_path = './transcriptomics/GSE64810_mlhd_DESeq2_diffexp_DESeq2_outlier_trimmed_adjust.txt'\n",
    "data = transcriptomics.read_data(csv_path, \"\\t\")\n",
    "clean_data = transcriptomics.clean_data(data)\n",
    "data_edges = transcriptomics.prepare_data_edges(clean_data)\n",
    "rna_network = transcriptomics.prepare_rna_edges(data_edges)\n",
    "\n",
    "# build network with graph schema\n",
    "rna_edges = transcriptomics.build_edges(rna_network)\n",
    "rna_nodes, nodes_dict = transcriptomics.build_nodes(rna_network)\n",
    "rna_edges = transcriptomics.rework_edges(pd.DataFrame(rna_edges), nodes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(rna_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"rna_edges_rework.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = transcriptomics.rework_edges(pd.DataFrame(rna_edges), nodes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(rna_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Transcriptomics network is returned as both digital object (`rna_edges`, `rna_nodes`) and CSV files at _**graph/**_ (`rna_edges_version.csv`, `rna_nodes_version.csv`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type edges: <class 'list'>\n",
      "type nodes: <class 'list'>\n",
      "\n",
      "len edges: 3209\n",
      "len nodes: 3210\n",
      "\n",
      "attribute edges: Index(['subject_id', 'object_id', 'property_id', 'property_label',\n",
      "       'property_description', 'property_uri', 'reference_uri',\n",
      "       'reference_supporting_text', 'reference_date'],\n",
      "      dtype='object')\n",
      "attribute nodes: dict_keys(['id', 'semantic_groups', 'preflabel', 'name', 'synonyms', 'description'])\n"
     ]
    }
   ],
   "source": [
    "# print type of objects\n",
    "print('type edges:', type(rna_edges))\n",
    "print('type nodes:', type(rna_nodes))\n",
    "print()\n",
    "\n",
    "# print objects sizes\n",
    "print('len edges:', len(rna_edges))\n",
    "print('len nodes:', len(rna_nodes))\n",
    "print()\n",
    "\n",
    "# print object attribute\n",
    "print('attribute edges:', rna_edges[0].keys())\n",
    "print('attribute nodes:', rna_nodes[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REGULATION NETWORK\n",
    "#### import regulation\n",
    "\n",
    "We retrieved human TF gene expression regulation edges from several sources using the `regulation` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The function \"prepare_msigdb_data()\" is running...\n",
      "\n",
      "* Number of Transcription Factor Targets (TFT) gene sets: 615\n",
      "\n",
      "The MSigDB raw network is saved at: /home/karolis/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer/regulation/msigdb/out/tf_genelist_entrez_msigdb.json. Other reporting files are also saved at the same directory.\n",
      "\n",
      "\n",
      "Finished prepare_msigdb_data().\n",
      "\n",
      "\n",
      "The function \"load_tf_gene_edges()\" is running...\n",
      "\n",
      "Finished load_tf_gene_edges().\n",
      "\n",
      "\n",
      "The function \"get_gene_id_normalization_dictionaries()\" is running...\n",
      "\n",
      "* Querying BioThings to map gene symbols to HGNC and Entrez IDs...\n",
      "querying 1-1000...done.\n",
      "querying 1001-2000...done.\n",
      "querying 2001-3000...done.\n",
      "querying 3001-3071...done.\n",
      "Finished.\n",
      "50 input query terms found no hit:\n",
      "\t['SIN3AK20', 'HMEF2', 'CREL', 'T3R', 'GNCF', 'MYOGNF1', 'COREBINDINGFACTOR', 'AHRARNT', 'E2F4DP1', '\n",
      "Pass \"returnall=True\" to return complete lists of duplicate or missing query terms.\n",
      "\n",
      "Saving not found gene symbols at: /home/karolis/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer/regulation/not_found_symbols.list\n",
      "\n",
      "\n",
      "* Querying BioThings to map Entrez to HGNC IDs and gene symbols...\n",
      "querying 1-1000...done.\n",
      "querying 1001-2000...done.\n",
      "querying 2001-3000...done.\n",
      "querying 3001-4000...done.\n",
      "querying 4001-5000...done.\n",
      "querying 5001-6000...done.\n",
      "querying 6001-7000...done.\n",
      "querying 7001-8000...done.\n",
      "querying 8001-9000...done.\n",
      "querying 9001-10000...done.\n",
      "querying 10001-11000...done.\n",
      "querying 11001-12000...done.\n",
      "querying 12001-13000...done.\n",
      "querying 13001-14000...done.\n",
      "querying 14001-15000...done.\n",
      "querying 15001-16000...done.\n",
      "querying 16001-16632...done.\n",
      "Finished.\n",
      "148 input query terms found no hit:\n",
      "\t['101243544', '284505', '338850', '257357', '126913', '9220', '84796', '200058', '285229', '283035',\n",
      "Pass \"returnall=True\" to return complete lists of duplicate or missing query terms.\n",
      "\n",
      "Saving not found Entrez gene IDs at: /home/karolis/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer/regulation/not_found_entrez.list\n",
      "\n",
      "\n",
      "Finished get_gene_id_normalization_dictionaries().\n",
      "\n",
      "\n",
      "The function \"prepare_data_edges()\" is running...\n",
      "\n",
      "The tftargets edges are saved at: /home/karolis/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer/regulation/tftargets/tftargets_edges.csv\n",
      "\n",
      "\n",
      "The MSigDB edges are saved at: /home/karolis/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer/regulation/msigdb/msigdb_edges.csv\n",
      "\n",
      "\n",
      "Finished prepare_data_edges().\n",
      "\n",
      "\n",
      "The function \"prepare_regulation_edges()\" is running...\n",
      "\n",
      "Finished prepare_regulation_edges().\n",
      "\n",
      "\n",
      "The function \"build_edges()\" is running...\n",
      "\n",
      "* This is the size of the edges file data structure: (197267, 9)\n",
      "* These are the edges attributes: Index(['subject_id', 'object_id', 'property_id', 'property_label',\n",
      "       'property_description', 'property_uri', 'reference_uri',\n",
      "       'reference_supporting_text', 'reference_date'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "  subject_id  object_id property_id  property_label property_description  \\\n",
      "0  HGNC:8615  HGNC:8803  RO:0002434  interacts with                   NA   \n",
      "\n",
      "                                property_uri  \\\n",
      "0  http://purl.obolibrary.org/obo/RO_0002434   \n",
      "\n",
      "                                  reference_uri  \\\n",
      "0  https://www.ncbi.nlm.nih.gov/pubmed/17202159   \n",
      "\n",
      "                           reference_supporting_text reference_date  \n",
      "0  This edge comes from the TRED dataset in \"tfta...     2007-01-01  \n",
      "\n",
      "The regulation network edges are built and saved at: /home/karolis/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer/graph/regulation_edges_v2022-04-06.csv\n",
      "\n",
      "\n",
      "Finished build_edges().\n",
      "\n",
      "\n",
      "The function \"build_nodes()\" is running...\n",
      "\n",
      "* Total number of nodes: 16969\n",
      "\n",
      "* Trap genes without gene symbol, i.e. genes with discontinued entrez ID...\n",
      "* Number of concepts without gene symbol: 148\n",
      "* Check that all genes without gene symbol are identified by entrez ID...\n",
      "* Number of concepts without gene symbol by namespace:  NCBIGene    148\n",
      "Name: id, dtype: int64\n",
      "\n",
      "* Querying BioThings to map retired Entrez to gene symbols...\n",
      "querying 1-148...done.\n",
      "Finished.\n",
      "90 input query terms found no hit:\n",
      "\t['79907', '79911', '93333', '121301', '143902', '146856', '151720', '197379', '219392', '221943', '2\n",
      "Pass \"returnall=True\" to return complete lists of duplicate or missing query terms.\n",
      "\n",
      "* Querying BioThings to retrieve node attributes...\n",
      "querying 1-1000...done.\n",
      "querying 1001-2000...done.\n",
      "querying 2001-3000...done.\n",
      "querying 3001-4000...done.\n",
      "querying 4001-5000...done.\n",
      "querying 5001-6000...done.\n",
      "querying 6001-7000...done.\n",
      "querying 7001-8000...done.\n",
      "querying 8001-9000...done.\n",
      "querying 9001-10000...done.\n",
      "querying 10001-11000...done.\n",
      "querying 11001-12000...done.\n",
      "querying 12001-13000...done.\n",
      "querying 13001-14000...done.\n",
      "querying 14001-15000...done.\n",
      "querying 15001-16000...done.\n",
      "querying 16001-16840...done.\n",
      "Finished.\n",
      "50 input query terms found no hit:\n",
      "\t['HMEF2', 'GNCF', 'CETS1P54', 'NKX25', 'CACBINDINGPROTEIN', 'CEBPGAMMA', 'AP1FJ', 'TAXCREB', 'PTF1BE\n",
      "Pass \"returnall=True\" to return complete lists of duplicate or missing query terms.\n",
      "\n",
      "* This is the size of the nodes file data structure: (16969, 6)\n",
      "* These are the nodes attributes: Index(['id', 'semantic_groups', 'preflabel', 'name', 'synonyms',\n",
      "       'description'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "          id semantic_groups preflabel          name    synonyms  \\\n",
      "0  HGNC:8615            GENE      PAX1  paired box 1  HUP48|OFC2   \n",
      "\n",
      "                                         description  \n",
      "0  This gene is a member of the paired box (PAX) ...  \n",
      "\n",
      "The regulation network nodes are built and saved at: /home/karolis/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer/graph/regulation_nodes_v2022-04-06.csv\n",
      "\n",
      "\n",
      "Finished build_nodes().\n",
      "\n",
      "CPU times: user 1min, sys: 235 ms, total: 1min\n",
      "Wall time: 2min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# prepare msigdb data\n",
    "gmt_path = './regulation/msigdb/data/c3.tft.v6.1.entrez.gmt'\n",
    "regulation.prepare_msigdb_data(gmt_path)\n",
    "\n",
    "# prepare individual networks\n",
    "data = regulation.load_tf_gene_edges()\n",
    "dicts = regulation.get_gene_id_normalization_dictionaries(data)\n",
    "data_edges = regulation.prepare_data_edges(data, dicts)\n",
    "\n",
    "# prepare regulation network\n",
    "reg_network = regulation.prepare_regulation_edges(data_edges)\n",
    "\n",
    "# build network with graph schema\n",
    "reg_edges = regulation.build_edges(reg_network)\n",
    "reg_nodes = regulation.build_nodes(reg_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Regulation network is returned as both digital object (`reg_edges`, `reg_nodes`) and CSV files at _**graph/**_ (`regulation_edges_version.csv`, `regulation_nodes_version.csv`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reg_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type edges: <class 'list'>\n",
      "type nodes: <class 'list'>\n",
      "\n",
      "len edges: 197267\n",
      "len nodes: 16969\n",
      "\n",
      "attribute edges: dict_keys(['subject_id', 'object_id', 'property_id', 'property_label', 'property_description', 'property_uri', 'reference_uri', 'reference_supporting_text', 'reference_date'])\n",
      "attribute nodes: dict_keys(['id', 'semantic_groups', 'preflabel', 'name', 'synonyms', 'description'])\n"
     ]
    }
   ],
   "source": [
    "# print type of objects\n",
    "print('type edges:', type(reg_edges))\n",
    "print('type nodes:', type(reg_nodes))\n",
    "print()\n",
    "\n",
    "# print objects sizes\n",
    "print('len edges:', len(reg_edges))\n",
    "print('len nodes:', len(reg_nodes))\n",
    "print()\n",
    "\n",
    "# print object attribute\n",
    "print('attribute edges:', reg_edges[0].keys())\n",
    "print('attribute nodes:', reg_nodes[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CURATED NETWORK\n",
    "#### import curation\n",
    "\n",
    "We retrieved and prepared curated edges using the `curation` module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "curation_edges = pd.read_csv(\"curation/data/HD/Empty_edges.csv\")\n",
    "curation_nodes = pd.read_csv(\"curation/data/HD/Empty_nodes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "curation_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The function \"read_network()\" is running...\n",
      "\n",
      "Reading and concatenating all curated statements in the network...\n",
      "\n",
      "* Curation edge files concatenated shape: (131, 22)\n",
      "\n",
      "Reading and concatenating all curated nodes in the network...\n",
      "\n",
      "* Curation node files concatenated shape: (105, 9)\n",
      "\n",
      "Finished read_network().\n",
      "\n",
      "\n",
      "The function \"prepare_data_edges()\" is running...\n",
      "\n",
      "Preparing curated network...\n",
      "\n",
      "Saving curated network at curation/...\n",
      "\n",
      "*Curated edges data structure shape: (131, 9)\n",
      "*Curated edges data structure fields: Index(['subject_id', 'property_id', 'object_id', 'reference_uri',\n",
      "       'reference_supporting_text', 'reference_date', 'property_label',\n",
      "       'property_description', 'property_uri'],\n",
      "      dtype='object')\n",
      "\n",
      "The curated edges are saved at: /home/karolis/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer/curation/curated_edges_v2022-04-06.csv\n",
      "\n",
      "\n",
      "Finished prepare_data_edges().\n",
      "\n",
      "\n",
      "The function \"prepare_data_nodes()\" is running...\n",
      "\n",
      "Preparing curated nodes...\n",
      "\n",
      "Saving curated nodes at curation/...\n",
      "\n",
      "*Curated nodes data structure shape: (105, 5)\n",
      "*Curated nodes data structure fields: Index(['id', 'semantic_groups', 'preflabel', 'synonyms', 'description'], dtype='object')\n",
      "\n",
      "The curated nodes are saved at: /home/karolis/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer/curation/curated_nodes_v2022-04-06.csv\n",
      "\n",
      "\n",
      "Finished prepare_data_nodes().\n",
      "\n",
      "\n",
      "The function \"prepare_curated_edges()\" is running...\n",
      "\n",
      "Preparing curated edges to graph schema...\n",
      "\n",
      "Mapping genes to HGNC ID...\n",
      "\n",
      "Mapping genes to HGNC ID...\n",
      "querying 1-10...done.\n",
      "Finished.\n",
      "\n",
      "Adding diseases to MONDO ID network...\n",
      "\n",
      "Adding gene to protein network...\n",
      "querying 1-9...done.\n",
      "Finished.\n",
      "\n",
      "Drop duplicated gene-protein relations...\n",
      "\n",
      "Finished prepare_curated_edges().\n",
      "\n",
      "\n",
      "The function \"prepare_curated_nodes()\" is running...\n",
      "\n",
      "Preparing curated nodes to graph schema...\n",
      "\n",
      "Mapping genes to HGNC ID...\n",
      "\n",
      "* Querying BioThings to map Entrez gene IDs to HGNC IDs...\n",
      "querying 1-10...done.\n",
      "Finished.\n",
      "\n",
      "Adding diseases described by the MONDO ontology...\n",
      "\n",
      "Adding Name attribute: gene names from BioThings...\n",
      "\n",
      "* Querying BioThings to map gene symbols to name...\n",
      "querying 1-116...done.\n",
      "Finished.\n",
      "104 input query terms found no hit:\n",
      "\t['hereditary spastic paraplegia', 'NGLY1-deficiency', 'Riley-Day syndrome', 'CharcotâMarieâTooth dis\n",
      "Pass \"returnall=True\" to return complete lists of duplicate or missing query terms.\n",
      "\n",
      "Preparing encoding genes from ngly1 curated network...\n",
      "\n",
      "Adding BioThings annotation: gene symbol, name, synonyms, description...\n",
      "\n",
      "* Querying BioThings to map UniProt IDs to HGNC IDs, gene symbol, name, aliases, and description...\n",
      "querying 1-9...done.\n",
      "Finished.\n",
      "\n",
      "Finished prepare_curated_nodes().\n",
      "\n",
      "\n",
      "The function \"build_edges()\" is running...\n",
      "\n",
      "Save curated graph edges file at graph/...\n",
      "\n",
      "* This is the size of the edges file data structure: (148, 10)\n",
      "* These are the edges attributes: Index(['subject_id', 'object_id', 'property_id', 'property_label',\n",
      "       'property_description', 'property_uri', 'reference_uri',\n",
      "       'reference_supporting_text', 'reference_date', 'g2p_mark'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "       subject_id    object_id      property_id property_label  \\\n",
      "0  UniProt:Q96IV0  EC:3.5.1.52  skos:exactMatch    exact match   \n",
      "\n",
      "  property_description property_uri  \\\n",
      "0                  NaN          NaN   \n",
      "\n",
      "                                  reference_uri  \\\n",
      "0  https://www.ncbi.nlm.nih.gov/pubmed/24651605   \n",
      "\n",
      "                           reference_supporting_text reference_date g2p_mark  \n",
      "0  The enzyme N-glycanase 1 (NGLY1), also known a...     2014-03-20        0  \n",
      "\n",
      "The curation network edges are built and saved at: /home/karolis/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer/graph/curated_graph_edges_v2022-04-06.csv\n",
      "\n",
      "\n",
      "Finished build_edges().\n",
      "\n",
      "\n",
      "The function \"build_nodges()\" is running...\n",
      "\n",
      "Save curated graph nodes file at graph/...\n",
      "\n",
      "* This is the size of the nodes file data structure: (116, 6)\n",
      "* These are the nodes attributes: Index(['id', 'semantic_groups', 'preflabel', 'name', 'synonyms',\n",
      "       'description'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "          id semantic_groups                      preflabel name  \\\n",
      "0  DOID:2476            DISO  hereditary spastic paraplegia  NaN   \n",
      "\n",
      "                                            synonyms  \\\n",
      "0  familial spastic paraplegia|French settlement ...   \n",
      "\n",
      "                                         description  \n",
      "0  A paraplegia that is characterized by progress...  \n",
      "\n",
      "The curation network nodes are built and saved at: /home/karolis/LUMC/HDSR/bioknowledge-reviewer/bioknowledge_reviewer/graph/curated_graph_nodes_v2022-04-06.csv\n",
      "\n",
      "\n",
      "Finished build_nodes().\n",
      "\n",
      "CPU times: user 1.64 s, sys: 432 ms, total: 2.07 s\n",
      "Wall time: 9.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# graph v3.2\n",
    "# read network from drive and concat all curated statements\n",
    "curation_edges, curation_nodes = curation.read_network(version='HD')\n",
    "\n",
    "# prepare data edges and nodes\n",
    "data_edges = curation.prepare_data_edges(curation_edges)\n",
    "data_nodes = curation.prepare_data_nodes(curation_nodes)\n",
    "\n",
    "# prepare curated edges and nodes\n",
    "curated_network = curation.prepare_curated_edges(data_edges)\n",
    "curated_concepts = curation.prepare_curated_nodes(data_nodes)\n",
    "\n",
    "\n",
    "# build edges and nodes files\n",
    "curation_edges = curation.build_edges(curated_network)\n",
    "curation_nodes = curation.build_nodes(curated_concepts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Curated network is returned as both digital object (`curation_edges`, `curation_nodes`) and CSV files at _**graph/**_ (`curated_graph_edges_version.csv`, `curated_graph_nodes_version.csv`)\n",
    "- The original curated network, i.e. without graph data model normalization, is saved as CSV files at _**curation/**_ (`curated_edges_version.csv`, `curated_nodes_version.csv`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type edges: <class 'list'>\n",
      "type nodes: <class 'list'>\n",
      "\n",
      "len edges: 148\n",
      "len nodes: 116\n",
      "\n",
      "attribute edges: dict_keys(['subject_id', 'object_id', 'property_id', 'property_label', 'property_description', 'property_uri', 'reference_uri', 'reference_supporting_text', 'reference_date', 'g2p_mark'])\n",
      "attribute nodes: dict_keys(['id', 'semantic_groups', 'preflabel', 'name', 'synonyms', 'description'])\n"
     ]
    }
   ],
   "source": [
    "# print type of objects\n",
    "print('type edges:', type(curation_edges))\n",
    "print('type nodes:', type(curation_nodes))\n",
    "print()\n",
    "\n",
    "# print objects sizes\n",
    "print('len edges:', len(curation_edges))\n",
    "print('len nodes:', len(curation_nodes))\n",
    "print()\n",
    "\n",
    "# print object attribute\n",
    "print('attribute edges:', curation_edges[0].keys())\n",
    "print('attribute nodes:', curation_nodes[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MONARCH NETWORK\n",
    "#### import monarch\n",
    "We retrieved edges from Monarch using the `monarch` module.\n",
    "\n",
    "Tasks:\n",
    "\n",
    "- From 8 seed nodes we retrieved 1st shell nodes\n",
    "- From all seed and 1st shell nodes we retrieved ortho-phenotypes\n",
    "- We retrieved extra edges among all of them, i.e. extra connectivity between: seed, 1st shell, ortholog-phenotype nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# prepare data to graph schema\n",
    "# seed nodes\n",
    "seedList = [ \n",
    "    'MONDO:0007739', # HD\n",
    "    'HGNC:4851', # Htt\n",
    "    'HGNC:182293', # Rhes\n",
    "    'REACT:R-HSA-917937' #Iron uptake pathway\n",
    "] \n",
    "\n",
    "# get first shell of neighbours\n",
    "neighboursList = monarch.get_neighbours_list(seedList)\n",
    "print(len(neighboursList))\n",
    "# get second degree of neighbours\n",
    "monarch_network = monarch.get_connections(neighboursList)\n",
    "print(len(monarch_network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monarch.print_network(monarch_network, 'monarch_connections')\n",
    "\n",
    "# build network with graph schema \n",
    "monarch_edges = monarch.build_edges(monarch_network)\n",
    "monarch_nodes = monarch.build_nodes(monarch_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print type of objects\n",
    "print('type edges:', type(monarch_edges))\n",
    "print('type nodes:', type(monarch_nodes))\n",
    "print()\n",
    "\n",
    "# print objects sizes\n",
    "print('len edges:', len(monarch_edges))\n",
    "print('len nodes:', len(monarch_nodes))\n",
    "print()\n",
    "\n",
    "# print object attribute\n",
    "print('attribute edges:', monarch_edges[0].keys())\n",
    "print('attribute nodes:', monarch_nodes[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The function \"get_neighbours_list()\" is running. Its runtime may take some minutes. If you interrupt the process, you will lose all the nodes retrieved and you should start over the execution of this function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 3/3 [00:12<00:00,  4.16s/it]\n",
      "  0%|                                                                                                                                                                                | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished get_neighbours_list().\n",
      "\n",
      "905\n",
      "\n",
      "The function \"get_orthopheno_list()\" is running. Its runtime may take some hours. If you interrupt the process, you will lose all the nodes retrieved and you should start over the execution of this function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 3/3 [00:08<00:00,  2.84s/it]\n",
      "100%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 16/16 [00:20<00:00,  1.29s/it]\n",
      "  0%|                                                                                                                                                                              | 0/905 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished get_orthopheno_list().\n",
      "\n",
      "219\n",
      "\n",
      "The function \"get_orthopheno_list()\" is running. Its runtime may take some hours. If you interrupt the process, you will lose all the nodes retrieved and you should start over the execution of this function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 905/905 [39:51<00:00,  2.64s/it]\n",
      "  3%|ââââââ                                                                                                                                                           | 203/6347 [03:33<1:24:04,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: <class 'requests.exceptions.ConnectionError'>\n",
      "ENSEMBL:ENSSSCG00000039390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|ââââââââââââ                                                                                                                                                     | 449/6347 [08:02<1:19:41,  1.23it/s]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# prepare data to graph schema\n",
    "# seed nodes\n",
    "seedList = [ \n",
    "    'MONDO:0007739', # HD\n",
    "    'HGNC:4851', # Htt\n",
    "    'HGNC:182293', # Rhes\n",
    "] \n",
    "\n",
    "# get first shell of neighbours\n",
    "neighboursList = monarch.get_neighbours_list(seedList)\n",
    "print(len(neighboursList))\n",
    "\n",
    "# introduce animal model ortho-phenotypes for seed and 1st shell neighbors\n",
    "## For seed nodes:\n",
    "seed_orthophenoList = monarch.get_orthopheno_list(seedList)\n",
    "print(len(seed_orthophenoList))\n",
    "## For 1st shell nodes:\n",
    "neighbours_orthophenoList = monarch.get_orthopheno_list(neighboursList)\n",
    "print(len(neighbours_orthophenoList))\n",
    "\n",
    "# network nodes: seed + 1shell + ortholog-phentoype\n",
    "geneList = sum([seedList,\n",
    "                neighboursList,\n",
    "                #seed_orthophenoList,\n",
    "                #neighbours_orthophenoList\n",
    "               ], \n",
    "               [])\n",
    "print('genelist: ',len(geneList))\n",
    "\n",
    "# get Monarch network\n",
    "monarch_network = monarch.extract_edges(geneList)\n",
    "print('network: ',len(monarch_network))\n",
    "\n",
    "# save edges\n",
    "monarch.print_network(monarch_network, 'monarch_connections')\n",
    "\n",
    "# build network with graph schema \n",
    "monarch_edges = monarch.build_edges(monarch_network)\n",
    "monarch_nodes = monarch.build_nodes(monarch_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "monarch_network = monarch.read_connections(\"monarch_connections_v2020-11-15.csv\")\n",
    "monarch_edges = monarch.build_edges(monarch_network)\n",
    "monarch_nodes = monarch.build_nodes(monarch_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "monarch_edges = monarch.build_edges(monarch_network)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "monarch_nodes = monarch.build_nodes(monarch_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print type of objects\n",
    "print('type edges:', type(monarch_edges))\n",
    "print('type nodes:', type(monarch_nodes))\n",
    "print()\n",
    "\n",
    "# print objects sizes\n",
    "print('len edges:', len(monarch_edges))\n",
    "print('len nodes:', len(monarch_nodes))\n",
    "print()\n",
    "\n",
    "# print object attribute\n",
    "print('attribute edges:', monarch_edges[0].keys())\n",
    "print('attribute nodes:', monarch_nodes[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Monarch network is returned as both digital object (`monarch_edges`, `monarch_nodes`) and CSV files at _**monarch/**_ (`monarch_edges_version.csv`, `monarch_nodes_version.csv`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph library\n",
    "### Create the review knowledge graph\n",
    "#### import graph\n",
    "\n",
    "Tasks:\n",
    "\n",
    "* Load Networks and calculate graph nodes\n",
    "* Retrieve extra connectivity for the graph from Monarch\n",
    "* Build the review graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# load networks and calculate graph nodes\n",
    "graph_nodes_list, reg_graph_edges = graph.graph_nodes(\n",
    "    curation=curation_edges,\n",
    "    monarch=monarch_edges,\n",
    "    transcriptomics=rna_edges,\n",
    "    regulation=reg_edges\n",
    ")\n",
    "\n",
    "# Monarch graph connectivity\n",
    "## get Monarch edges\n",
    "monarch_network_graph = monarch.extract_edges(graph_nodes_list)\n",
    "print('network: ',len(monarch_network_graph))\n",
    "\n",
    "## save Monarch network\n",
    "monarch.print_network(monarch_network_graph, 'monarch_connections_graph')\n",
    "\n",
    "## build Monarch network with graph schema\n",
    "monarch_graph_edges = monarch.build_edges(monarch_network_graph)\n",
    "monarch_graph_nodes = monarch.build_nodes(monarch_network_graph)\n",
    "\n",
    "# build review graph\n",
    "edges = graph.build_edges(\n",
    "    curation=curation_edges,\n",
    "    monarch=monarch_graph_edges,\n",
    "    transcriptomics=rna_edges,\n",
    "    regulation=reg_graph_edges\n",
    ")\n",
    "nodes = graph.build_nodes(\n",
    "    statements=edges,\n",
    "    curation=curation_nodes,\n",
    "    monarch=monarch_graph_nodes,\n",
    "    transcriptomics=rna_nodes,\n",
    "    regulation=reg_nodes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# obtain variables:\n",
    "curation_edges = pd.read_csv(\"curation/data/HD/Empty_edges.csv\")\n",
    "curation_nodes = pd.read_csv(\"curation/data/HD/Empty_nodes.csv\")\n",
    "\n",
    "#monarch_network = monarch.read_connections(\"monarch_connections_v2020-11-15.csv\")\n",
    "#monarch_edges = monarch.build_edges(monarch_network)\n",
    "#monarch_nodes = monarch.build_nodes(monarch_network)\n",
    "\n",
    "#monarch_network_graph = monarch.read_connections(\"monarch_connections_graph_v2020-11-16.csv\")\n",
    "#monarch_graph_edges = monarch.build_edges(monarch_network_graph)\n",
    "#monarch_graph_nodes = monarch.build_nodes(monarch_network_graph)\n",
    "\n",
    "csv_path = './transcriptomics/GSE64810_mlhd_DESeq2_diffexp_DESeq2_outlier_trimmed_adjust.txt'\n",
    "data = transcriptomics.read_data(csv_path)\n",
    "clean_data = transcriptomics.clean_data(data)\n",
    "data_edges = transcriptomics.prepare_data_edges(clean_data)\n",
    "rna_network = transcriptomics.prepare_rna_edges(data_edges)\n",
    "\n",
    "# build network with graph schema\n",
    "rna_edges = transcriptomics.build_edges(rna_network)\n",
    "rna_nodes = transcriptomics.build_nodes(rna_network)\n",
    "\n",
    "gmt_path = './regulation/msigdb/data/c3.tft.v6.1.entrez.gmt'\n",
    "regulation.prepare_msigdb_data(gmt_path)\n",
    "\n",
    "# prepare individual networks\n",
    "data = regulation.load_tf_gene_edges()\n",
    "dicts = regulation.get_gene_id_normalization_dictionaries(data)\n",
    "data_edges = regulation.prepare_data_edges(data, dicts)\n",
    "\n",
    "# prepare regulation network\n",
    "reg_network = regulation.prepare_regulation_edges(data_edges)\n",
    "\n",
    "# build network with graph schema\n",
    "reg_edges = regulation.build_edges(reg_network)\n",
    "reg_nodes = regulation.build_nodes(reg_network)\n",
    "\n",
    "#graph_nodes_list, reg_graph_edges = graph.graph_nodes(\n",
    "#    curation=curation_edges,\n",
    "#    monarch=monarch_edges,\n",
    "#    transcriptomics=rna_edges,\n",
    "#    regulation=reg_edges\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix curation data:\n",
    "curation_nodes = curation_nodes.astype('object')\n",
    "#curation_nodes.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curation_nodes['name'] = [\"NaN\", \"NaN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curation_nodes.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# construct df's\n",
    "edges = graph.build_edges(\n",
    "    curation=curation_edges,\n",
    "    monarch=monarch_graph_edges,\n",
    "    transcriptomics=rna_edges,\n",
    "    regulation=reg_graph_edges\n",
    ")\n",
    "nodes = graph.build_nodes(\n",
    "    statements=edges,\n",
    "    curation=curation_nodes,\n",
    "    monarch=monarch_graph_nodes,\n",
    "    transcriptomics=rna_nodes,\n",
    "    regulation=reg_nodes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.read_csv(\"/home/karolis/Structured review/bioknowledge-reviewer/bioknowledge_reviewer/graph/graph_nodes_v2020-11-20.csv\")\n",
    "edges = pd.read_csv(\"/home/karolis/Structured review/bioknowledge-reviewer/bioknowledge_reviewer/graph/graph_edges_v2020-11-20.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Regulation edges _merged_ with the graph is returned as both digital object (`reg_graph_edges`) and CSV file at _**graph/**_ (`regulation_graph_edges_version.csv`)\n",
    "- Monarch network is returned as both digital object (`monarch_graph_edges`, `monarch_graph_nodes`) and CSV files at _**monarch/**_ (`monarch_edges_version.csv`, `monarch_nodes_version.csv`) overwritten the previous one.\n",
    "- Review knowledge graph is returned as both digital object (`edges`, `nodes`) and CSV files at _**graph/**_ (`graph_edges_version.csv`, `graph_nodes_version.csv`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print type of objects\n",
    "print('type edges:', type(edges))\n",
    "print('type nodes:', type(nodes))\n",
    "print()\n",
    "\n",
    "# print objects sizes\n",
    "print('len edges:', len(edges))\n",
    "print('len nodes:', len(nodes))\n",
    "print()\n",
    "\n",
    "# print object attribute\n",
    "print('attribute edges:', edges.columns)\n",
    "print('attribute nodes:', nodes.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neo4jlib library\n",
    "### Import the graph into Neo4j graph database\n",
    "#### import neo4jlib\n",
    "\n",
    "Tasks:\n",
    "\n",
    "- Create Neo4j server instance\n",
    "- Import review graph into the Neo4j graph database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curation_edges = pd.read_csv(\"curation/data/HD/Empty_edges.csv\")\n",
    "curation_nodes = pd.read_csv(\"curation/data/HD/Empty_nodes.csv\")\n",
    "curation_nodes = curation_nodes.astype('object')\n",
    "curation_nodes['name'] = [\"NaN\", \"NaN\"]\n",
    "curation_edges = curation_edges.to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# obtain variables:\n",
    "#curation_edges = pd.read_csv(\"curation/data/HD/Empty_edges.csv\")\n",
    "#curation_nodes = pd.read_csv(\"curation/data/HD/Empty_nodes.csv\")\n",
    "\n",
    "monarch_network = monarch.read_connections(\"monarch_connections_v2020-12-12.csv\")\n",
    "monarch_edges = monarch.build_edges(monarch_network)\n",
    "monarch_nodes = monarch.build_nodes(monarch_network)\n",
    "\n",
    "#monarch_network_graph = monarch.read_connections(\"monarch_connections_graph_v2020-12-02.csv\")\n",
    "#monarch_graph_edges = monarch.build_edges(monarch_network_graph)\n",
    "#monarch_graph_nodes = monarch.build_nodes(monarch_network_graph)\n",
    "\n",
    "#csv_path = './transcriptomics/GSE64810_mlhd_DESeq2_diffexp_DESeq2_outlier_trimmed_adjust.txt'\n",
    "#data = transcriptomics.read_data(csv_path, \"\\t\")\n",
    "#clean_data = transcriptomics.clean_data(data)\n",
    "#data_edges = transcriptomics.prepare_data_edges(clean_data)\n",
    "#rna_network = transcriptomics.prepare_rna_edges(data_edges)\n",
    "\n",
    "# build network with graph schema\n",
    "#rna_edges = transcriptomics.build_edges(rna_network)\n",
    "#rna_nodes, rna_edges = transcriptomics.build_nodes(rna_network)\n",
    "csv_path = './transcriptomics/GSE64810_mlhd_DESeq2_diffexp_DESeq2_outlier_trimmed_adjust.txt'\n",
    "data = transcriptomics.read_data(csv_path, \"\\t\")\n",
    "clean_data = transcriptomics.clean_data(data)\n",
    "data_edges = transcriptomics.prepare_data_edges(clean_data)\n",
    "rna_network = transcriptomics.prepare_rna_edges(data_edges)\n",
    "\n",
    "# build network with graph schema\n",
    "rna_edges = transcriptomics.build_edges(rna_network)\n",
    "rna_nodes, nodes_dict = transcriptomics.build_nodes(rna_network)\n",
    "\n",
    "\n",
    "gmt_path = './regulation/msigdb/data/c3.tft.v6.1.entrez.gmt'\n",
    "regulation.prepare_msigdb_data(gmt_path)\n",
    "\n",
    "# prepare individual networks\n",
    "data = regulation.load_tf_gene_edges()\n",
    "dicts = regulation.get_gene_id_normalization_dictionaries(data)\n",
    "data_edges = regulation.prepare_data_edges(data, dicts)\n",
    "\n",
    "# prepare regulation network\n",
    "reg_network = regulation.prepare_regulation_edges(data_edges)\n",
    "\n",
    "# build network with graph schema\n",
    "reg_edges = regulation.build_edges(reg_network)\n",
    "reg_nodes = regulation.build_nodes(reg_network)\n",
    "\n",
    "#graph_nodes_list, reg_graph_edges = graph.graph_nodes(\n",
    "#    curation=curation_edges,\n",
    "#    monarch=monarch_edges,\n",
    "#    transcriptomics=rna_edges,\n",
    "#    regulation=reg_edges\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curation_edges = pd.DataFrame(curation_edges)\n",
    "monarch_edges = pd.DataFrame(monarch_edges)\n",
    "rna_edges = pd.DataFrame(rna_edges)\n",
    "curation_edges = curation_edges.iloc[0]\n",
    "curation_edges = pd.DataFrame(curation_edges).T\n",
    "reg_edges = pd.DataFrame(reg_edges)\n",
    "curation_nodes = curation_nodes.iloc[0]\n",
    "curation_nodes = pd.DataFrame(curation_nodes).T\n",
    "monarch_nodes = pd.DataFrame(monarch_nodes)\n",
    "rna_nodes = pd.DataFrame(rna_nodes)\n",
    "reg_nodes = pd.DataFrame(reg_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "monarch_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curation_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "monarch_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# load networks and calculate graph nodes\n",
    "graph_nodes_list, reg_graph_edges = graph.graph_nodes(\n",
    "    curation=curation_edges,\n",
    "    monarch=monarch_edges,\n",
    "    transcriptomics=rna_edges,\n",
    "    regulation=reg_edges\n",
    ")\n",
    "\n",
    "# Monarch graph connectivity\n",
    "## get Monarch edges\n",
    "monarch_network_graph = monarch.extract_edges(graph_nodes_list)\n",
    "print('network: ',len(monarch_network_graph))\n",
    "\n",
    "## save Monarch network\n",
    "monarch.print_network(monarch_network_graph, 'monarch_connections_graph')\n",
    "\n",
    "## build Monarch network with graph schema\n",
    "monarch_graph_edges = monarch.build_edges(monarch_network_graph)\n",
    "monarch_graph_nodes = monarch.build_nodes(monarch_network_graph)\n",
    "\n",
    "# build review graph\n",
    "edges = graph.build_edges(\n",
    "    curation=curation_edges,\n",
    "    monarch=monarch_graph_edges,\n",
    "    transcriptomics=rna_edges,\n",
    "    regulation=reg_graph_edges\n",
    ")\n",
    "nodes = graph.build_nodes(\n",
    "    statements=edges,\n",
    "    curation=curation_nodes,\n",
    "    monarch=monarch_graph_nodes,\n",
    "    transcriptomics=rna_nodes,\n",
    "    regulation=reg_nodes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_graph_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_df = pd.read_csv(\"./graph/graph_edges_v2021-04-12_alt_del.csv\")\n",
    "nodes_df = pd.read_csv(\"./graph/graph_nodes_v2021-04-12.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# create a Neo4j server instance\n",
    "neo4j_dir = neo4jlib.create_neo4j_instance('4.2.1')\n",
    "print('The name of the neo4j directory is {}'.format(neo4j_dir))\n",
    "\n",
    "# import to graph database\n",
    "## prepare the graph to neo4j format\n",
    "#edges_df = utils.get_dataframe(edges)\n",
    "#nodes_df = utils.get_dataframe(nodes)\n",
    "statements = neo4jlib.get_statements(edges_df)\n",
    "concepts = neo4jlib.get_concepts(nodes_df)\n",
    "print('statements: ', len(statements))\n",
    "print('concepts: ',len(concepts))\n",
    "\n",
    "## save files into neo4j import dir\n",
    "neo4j_path = './{}'.format(neo4j_dir)\n",
    "neo4jlib.save_neo4j_files(statements, neo4j_path, file_type = 'statements')\n",
    "neo4jlib.save_neo4j_files(concepts, neo4j_path, file_type = 'concepts')\n",
    "\n",
    "## import graph into neo4j database\n",
    "neo4jlib.do_import(neo4j_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print type of objects\n",
    "print('type edges:', type(statements))\n",
    "print('type nodes:', type(concepts))\n",
    "print()\n",
    "\n",
    "# print objects sizes\n",
    "print('len edges:', len(statements))\n",
    "print('len nodes:', len(concepts))\n",
    "print()\n",
    "\n",
    "# print object attribute\n",
    "print('attribute edges:', statements.columns)\n",
    "print('attribute nodes:', concepts.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hypothesis-generation library\n",
    "### Query the graph for mechanistic explanation, then summarize the extracted paths\n",
    "#### import hypothesis, summary\n",
    "\n",
    "\n",
    "Tasks:\n",
    "\n",
    "* Retrieve orthopheno paths with the `query` method.\n",
    "* Retrieve orthopheno paths using relaxing node degree parameters with the `query` method.\n",
    "* Retrieve orthopheno paths from a more open query topology with the `open_query` method.\n",
    "* Get hypothesis summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ortopheno query with general nodes/relations removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import sys,os\n",
    "import json\n",
    "import yaml\n",
    "import datetime\n",
    "import neo4j.exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_path( path ):\n",
    "    \"\"\"\n",
    "    This function parses neo4j results.\n",
    "    :param path: neo4j path object\n",
    "    :return: parsed path dictionary\n",
    "    \"\"\"\n",
    "\n",
    "    out = {}\n",
    "    out['Nodes'] = []\n",
    "    for node in path['path'].nodes:\n",
    "        n = {}\n",
    "        n['idx'] = node.id\n",
    "        n['label'] = list(node.labels)[0]\n",
    "        n['id'] = node.get('id')\n",
    "        n['preflabel'] = node.get('preflabel')\n",
    "        n['name'] = node.get('name')\n",
    "        n['description'] = node.get('description')\n",
    "        out['Nodes'].append(n)\n",
    "    out['Edges'] = []\n",
    "    for edge in path['path'].relationships:\n",
    "        e = {}\n",
    "        e['idx'] = edge.id\n",
    "        e['start_node'] = edge.start_node.id\n",
    "        e['end_node'] = edge.end_node.id\n",
    "        e['type'] = edge.type\n",
    "        e['preflabel'] = edge.get('property_label')\n",
    "        e['references'] = edge.get('reference_uri')\n",
    "        out['Edges'].append(e)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node(source, target, port='7687'):\n",
    "    \"\"\"\n",
    "    This function checks if a node exists within the graph\n",
    "    \"\"\"\n",
    "    try:\n",
    "        driver = GraphDatabase.driver(\"bolt://localhost:{}\".format(port), auth=(\"neo4j\", \"ngly1\"))\n",
    "    except neo4j.exceptions.ServiceUnavailable:\n",
    "        raise\n",
    "    outputAll = list()\n",
    "    with driver.session() as session:\n",
    "        query = \"\"\"MATCH (source { id: '\"\"\" + source + \"\"\"' }), (target { id: '\"\"\" + target +  \"\"\"' }), p = allShortestPaths((source)-[*..15]-(target)) RETURN p\"\"\"\n",
    "        result = session.run(query)\n",
    "        print(result)\n",
    "        x = []\n",
    "        for record in result:\n",
    "            #path_dct = parse_path(record)\n",
    "            x.append(record)\n",
    "        print(x)\n",
    "        return x, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x, result = get_node('HGNC:4851', 'HGNC:18229')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.consume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_shortest_paths(source, target, max_length=4, port='7687'):\n",
    "    \"\"\"\n",
    "    This function gets the shortest paths between source and\n",
    "    target. max_length determines the maximum path size allowed.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        driver = GraphDatabase.driver(\"bolt://localhost:{}\".format(port), auth=(\"neo4j\", \"ngly1\"))\n",
    "    except neo4j.exceptions.ServiceUnavailable:\n",
    "        raise\n",
    "    outputAll = list()\n",
    "    with driver.session() as session:\n",
    "        print(\"kaas\")\n",
    "        query = \"\"\"MATCH (source { id: '\"\"\" + source + \"\"\"' }), (target { id: '\"\"\" + target +  \"\"\"' }), p = shortestPath((source)-[*..15]-(target)) RETURN p\"\"\"\n",
    "        result = session.run(query)\n",
    "        print(result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seed = list([\n",
    "        'HGNC:4851',  # Htt human gene\n",
    "        'HGNC:18229'  # Rhes human gene\n",
    "])\n",
    "result = query_shortest_paths(seed[0], seed[1], max_length=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = result.consume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# get orthopheno paths\n",
    "seed = list([\n",
    "        'HGNC:4851',  # Htt human gene\n",
    "        'HGNC:18229'  # Rhes human gene\n",
    "])\n",
    "hypothesis.query(seed,queryname='Htt_Rhes',port='7687') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# get orthopheno paths relaxing pathway and phenotype node degrees\n",
    "seed = list([\n",
    "        'HGNC:4851',  # NGLY1 human gene\n",
    "        'HGNC:18229'  # AQP1 human gene\n",
    "])\n",
    "hypothesis.query(seed, queryname='Htt_Rhes', pwdegree='1000', phdegree='1000', port='7687')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# get orthopheno paths from a more open query topogology\n",
    "seed = list([\n",
    "        'HGNC:4851',  # NGLY1 human gene\n",
    "        'HGNC:18229'  # AQP1 human gene\n",
    "])\n",
    "hypothesis.open_query(seed,queryname='Htt_Rhes',port='7687')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "seed = list([\n",
    "        'HGNC:4851',  # NGLY1 human gene\n",
    "        'HGNC:18229'  # AQP1 human gene\n",
    "])\n",
    "r = hypothesis.shortest_paths(seed[0], seed[1], max_length=50, port='7687')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# get summary\n",
    "data = summary.path_load('./hypothesis/query_ngly1_aqp1_pwdl1000_phdl1000_paths_v2020-09-14.json')\n",
    "\n",
    "# parse data for summarization\n",
    "data_parsed = list()\n",
    "for query in data:\n",
    "    query_parsed = summary.query_parser(query)\n",
    "    data_parsed.append(query_parsed)\n",
    "summary.metapaths(data_parsed)\n",
    "summary.nodes(data_parsed)\n",
    "summary.node_types(data_parsed)\n",
    "summary.edges(data_parsed)\n",
    "summary.edge_types(data_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

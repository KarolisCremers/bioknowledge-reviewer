{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @name\n",
    "# @description\n",
    "# @author\n",
    "# @date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Description\n",
    "\n",
    "This is the notebook for the creation of the first review network and derived hypotheses. \n",
    "\n",
    "* Using intermediary variables from workflow objects. In this workflow variables are directly used for the next step. \n",
    "\n",
    "\n",
    "* Review network: From Monarch knowledge graph, we built a network seeded by 8 nodes, retrieving their explicit relationships and all the relationships among all these nodes. Seed nodes:\n",
    "\n",
    "    - 'MONDO:0014109', # NGLY1 deficiency\n",
    "    - 'HGNC:17646', # NGLY1 human gene\n",
    "    - 'HGNC:633', # AQP1 human gene\n",
    "    - 'MGI:103201', # AQP1 mouse gene\n",
    "    - 'HGNC:7781', # NRF1 human gene* Ginger: known as NFE2L1. http://biogps.org/#goto=genereport&id=4779\n",
    "    - 'HGNC:24622', # ENGASE human gene\n",
    "    - 'HGNC:636', # AQP3 human gene\n",
    "    - 'HGNC:19940' # AQP11 human gene\n",
    "    \n",
    "\n",
    "* Connecting paths: query templates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import time\n",
    "import transcriptomics, regulation, curation, monarch, graph, neo4jlib, hypothesis, summary, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edges library\n",
    "### Review edges to integrate into the knowledge graph\n",
    "#### import transcriptomics\n",
    "We retrieved edges from RNA-seq transcriptomics profiles using the transcriptomics module:\n",
    "\n",
    "    - Experimental data sets: from Chow et al. paper [pmid:29346549] (NGLY1 deficiency model on fruit fly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* This is the size of the raw expression data structure: (15370, 9)\n",
      "* These are the expression attributes: Index(['FlyBase ID', 'Symbol', 'baseMean', 'log2FoldChange', 'Unnamed: 4',\n",
      "       'lfcSE', 'stat', 'pvalue', 'padj'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "    FlyBase ID  Symbol    baseMean  log2FoldChange  Unnamed: 4     lfcSE  \\\n",
      "0  FBgn0030880  CG6788  175.577087       -4.209283     0.05406  0.190308   \n",
      "\n",
      "        stat         pvalue           padj  \n",
      "0 -22.118249  2.110000e-108  2.860000e-104  \n",
      "\n",
      "* This is the size of the clean expression data structure: (386, 6)\n",
      "* These are the clean expression attributes: Index(['FlyBase ID', 'Symbol', 'log2FoldChange', 'pvalue', 'padj',\n",
      "       'Regulation'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "    FlyBase ID Symbol  log2FoldChange        pvalue      padj   Regulation\n",
      "0  FBgn0035904  GstO3        0.576871  2.130000e-08  0.000002  Upregulated\n",
      "\n",
      "* This is the size of the expression data structure: (386, 13)\n",
      "* These are the expression attributes: Index(['flybase_id', 'symbol', 'log2FoldChange', 'pvalue', 'padj',\n",
      "       'regulation', 'source', 'subject_id', 'subject_label', 'property_id',\n",
      "       'property_label', 'reference_id', 'object_id'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "    flybase_id symbol  log2FoldChange        pvalue      padj   regulation  \\\n",
      "0  FBgn0035904  GstO3        0.576871  2.130000e-08  0.000002  Upregulated   \n",
      "\n",
      "  source           subject_id subject_label property_id  property_label  \\\n",
      "0   Chow  FlyBase:FBgn0033050          Pngl  RO:0002434  interacts with   \n",
      "\n",
      "    reference_id            object_id  \n",
      "0  PMID:29346549  FlyBase:FBgn0035904  \n",
      "\n",
      "* This is the size of the edges data structure: (386, 12)\n",
      "* These are the edges attributes: Index(['subject_id', 'subject_label', 'property_id', 'property_label',\n",
      "       'object_id', 'object_label', 'log2FoldChange', 'pvalue', 'fdr',\n",
      "       'regulation', 'source', 'reference_id'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "            subject_id subject_label property_id  property_label  \\\n",
      "0  FlyBase:FBgn0033050          Pngl  RO:0002434  interacts with   \n",
      "\n",
      "             object_id object_label  log2FoldChange        pvalue       fdr  \\\n",
      "0  FlyBase:FBgn0035904        GstO3        0.576871  2.130000e-08  0.000002   \n",
      "\n",
      "    regulation source   reference_id  \n",
      "0  Upregulated   Chow  PMID:29346549  \n",
      "\n",
      "* This is the size of the edges file data structure: (386, 9)\n",
      "* These are the edges attributes: Index(['object_id', 'property_description', 'property_id', 'property_label',\n",
      "       'property_uri', 'reference_date', 'reference_supporting_text',\n",
      "       'reference_uri', 'subject_id'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "             object_id property_description property_id  property_label  \\\n",
      "0  FlyBase:FBgn0035904                   NA  RO:0002434  interacts with   \n",
      "\n",
      "                                property_uri reference_date  \\\n",
      "0  http://purl.obolibrary.org/obo/RO_0002434     2018-03-15   \n",
      "\n",
      "                           reference_supporting_text  \\\n",
      "0  To understand how loss of NGLY1 contributes to...   \n",
      "\n",
      "                                  reference_uri           subject_id  \n",
      "0  https://www.ncbi.nlm.nih.gov/pubmed/29346549  FlyBase:FBgn0033050  \n",
      "* Total number of nodes: 386\n",
      "querying 1-386...done.\n",
      "Finished.\n",
      "\n",
      "* This is the size of the nodes file data structure: (386, 6)\n",
      "* These are the nodes attributes: Index(['description', 'id', 'name', 'preflabel', 'semantic_groups',\n",
      "       'synonyms'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "  description                   id         name preflabel semantic_groups  \\\n",
      "0         NaN  FlyBase:FBgn0033050  PNGase-like      Pngl            GENE   \n",
      "\n",
      "                         synonyms  \n",
      "0  CG7865|Dmel\\CG7865|PNGase|png1  \n",
      "CPU times: user 645 ms, sys: 39.7 ms, total: 685 ms\n",
      "Wall time: 2.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# prepare data to graph schema\n",
    "csv_path = './transcriptomics/ngly1-fly-chow-2018/data/supp_table_1.csv'\n",
    "data = transcriptomics.read_data(csv_path)\n",
    "clean_data = transcriptomics.clean_data(data)\n",
    "data_edges = transcriptomics.prepare_data_edges(clean_data)\n",
    "rna_network = transcriptomics.prepare_rna_edges(data_edges)\n",
    "\n",
    "# build network with graph schema\n",
    "rna_edges = transcriptomics.build_edges(rna_network)\n",
    "rna_nodes = transcriptomics.build_nodes(rna_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network is returned as both CSV files at graph/ and digital object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type edges: <class 'list'>\n",
      "type nodes: <class 'list'>\n",
      "\n",
      "len edges: 386\n",
      "len nodes: 386\n",
      "\n",
      "attribute edges: dict_keys(['subject_id', 'object_id', 'property_id', 'property_label', 'property_description', 'property_uri', 'reference_uri', 'reference_supporting_text', 'reference_date'])\n",
      "attribute nodes: dict_keys(['id', 'semantic_groups', 'preflabel', 'name', 'synonyms', 'description'])\n"
     ]
    }
   ],
   "source": [
    "# print type of objects\n",
    "print('type edges:', type(rna_edges))\n",
    "print('type nodes:', type(rna_nodes))\n",
    "print()\n",
    "\n",
    "# print objects sizes\n",
    "print('len edges:', len(rna_edges))\n",
    "print('len nodes:', len(rna_nodes))\n",
    "print()\n",
    "\n",
    "# print object attribute\n",
    "print('attribute edges:', rna_edges[0].keys())\n",
    "print('attribute nodes:', rna_nodes[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import regulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* Number of Transcription Factor Targets (TFT) gene sets: 615\n",
      "\n",
      "* Querying BioThings to map gene symbols to hgnc and entrez IDs...\n",
      "querying 1-1000...done.\n",
      "querying 1001-2000...done.\n",
      "querying 2001-3000...done.\n",
      "querying 3001-3071...done.\n",
      "Finished.\n",
      "53 input query terms found no hit:\n",
      "\t['NKX22', 'MEIS1BHOXA9', 'TAL1BETAE47', 'CEBPGAMMA', 'GNCF', 'NFKAPPAB65', 'E2F1DP1RB', 'MMEF2', 'E2\n",
      "Pass \"returnall=True\" to return complete lists of duplicate or missing query terms.\n",
      "\n",
      "* Querying BioThings to map entrez to hgnc IDs and gene symbols...\n",
      "querying 1-1000...done.\n",
      "querying 1001-2000...done.\n",
      "querying 2001-3000...done.\n",
      "querying 3001-4000...done.\n",
      "querying 4001-5000...done.\n",
      "querying 5001-6000...done.\n",
      "querying 6001-7000...done.\n",
      "querying 7001-8000...done.\n",
      "querying 8001-9000...done.\n",
      "querying 9001-10000...done.\n",
      "querying 10001-11000...done.\n",
      "querying 11001-12000...done.\n",
      "querying 12001-13000...done.\n",
      "querying 13001-14000...done.\n",
      "querying 14001-15000...done.\n",
      "querying 15001-16000...done.\n",
      "querying 16001-16632...done.\n",
      "Finished.\n",
      "138 input query terms found no hit:\n",
      "\t['347582', '339071', '439914', '9503', '339784', '121301', '283650', '200058', '401123', '79907', '4\n",
      "Pass \"returnall=True\" to return complete lists of duplicate or missing query terms.\n",
      "\n",
      "* This is the size of the edges file data structure: (197267, 9)\n",
      "* These are the edges attributes: Index(['object_id', 'property_description', 'property_id', 'property_label',\n",
      "       'property_uri', 'reference_date', 'reference_supporting_text',\n",
      "       'reference_uri', 'subject_id'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "   object_id property_description property_id  property_label  \\\n",
      "0  HGNC:8803                   NA  RO:0002434  interacts with   \n",
      "\n",
      "                                property_uri reference_date  \\\n",
      "0  http://purl.obolibrary.org/obo/RO_0002434     2007-01-01   \n",
      "\n",
      "                           reference_supporting_text  \\\n",
      "0  This edge comes from the TRED dataset in \"tfta...   \n",
      "\n",
      "                                  reference_uri subject_id  \n",
      "0  https://www.ncbi.nlm.nih.gov/pubmed/17202159  HGNC:8615  \n",
      "* Total number of nodes: 16963\n",
      "\n",
      "* Trap genes without gene symbol, i.e. genes with discontinued entrez ID...\n",
      "* Number of concepts without gene symbol: 138\n",
      "* Check that all genes without gene symbol are identified by entrez ID...\n",
      "* Number of concepts without gene symbol by namespace:  NCBIGene    138\n",
      "Name: id, dtype: int64\n",
      "\n",
      "* Querying BioThings to map retired entrez to gene symbols...\n",
      "querying 1-138...done.\n",
      "Finished.\n",
      "88 input query terms found no hit:\n",
      "\t['79907', '79911', '93333', '121301', '143902', '146856', '151720', '197379', '219392', '221943', '2\n",
      "Pass \"returnall=True\" to return complete lists of duplicate or missing query terms.\n",
      "\n",
      "* Querying BioThings to retrieve node attributes...\n",
      "querying 1-1000...done.\n",
      "querying 1001-2000...done.\n",
      "querying 2001-3000...done.\n",
      "querying 3001-4000...done.\n",
      "querying 4001-5000...done.\n",
      "querying 5001-6000...done.\n",
      "querying 6001-7000...done.\n",
      "querying 7001-8000...done.\n",
      "querying 8001-9000...done.\n",
      "querying 9001-10000...done.\n",
      "querying 10001-11000...done.\n",
      "querying 11001-12000...done.\n",
      "querying 12001-13000...done.\n",
      "querying 13001-14000...done.\n",
      "querying 14001-15000...done.\n",
      "querying 15001-16000...done.\n",
      "querying 16001-16842...done.\n",
      "Finished.\n",
      "53 input query terms found no hit:\n",
      "\t['NFKAPPAB65', 'E2F1DP1RB', 'PTF1BETA', 'TAL1BETAITF2', 'RORA1', 'MYCMAX', 'CREBP1', 'NKX62', 'ALPHA\n",
      "Pass \"returnall=True\" to return complete lists of duplicate or missing query terms.\n",
      "\n",
      "* This is the size of the nodes file data structure: (16963, 6)\n",
      "* These are the nodes attributes: Index(['description', 'id', 'name', 'preflabel', 'semantic_groups',\n",
      "       'synonyms'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "                                         description         id          name  \\\n",
      "0  This gene is a member of the paired box (PAX) ...  HGNC:8615  paired box 1   \n",
      "\n",
      "  preflabel semantic_groups    synonyms  \n",
      "0      PAX1            GENE  HUP48|OFC2  \n",
      "CPU times: user 2min 31s, sys: 564 ms, total: 2min 32s\n",
      "Wall time: 4min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# prepare msigdb data\n",
    "gmt_path = './regulation/msigdb/data/c3.tft.v6.1.entrez.gmt'\n",
    "regulation.prepare_msigdb_data(gmt_path)\n",
    "\n",
    "# prepare individual networks\n",
    "data = regulation.load_tf_gene_edges()\n",
    "dicts = regulation.get_gene_id_normalization_dictionaries(data)\n",
    "data_edges = regulation.prepare_data_edges(data, dicts)\n",
    "\n",
    "# prepare regulation network\n",
    "reg_network = regulation.prepare_regulation_edges(data_edges)\n",
    "\n",
    "# build network with graph schema\n",
    "reg_edges = regulation.build_edges(reg_network)\n",
    "reg_nodes = regulation.build_nodes(reg_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network is returned as both CSV file at graph/ and digital object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type edges: <class 'list'>\n",
      "type nodes: <class 'list'>\n",
      "\n",
      "len edges: 197267\n",
      "len nodes: 16963\n",
      "\n",
      "attribute edges: dict_keys(['subject_id', 'object_id', 'property_id', 'property_label', 'property_description', 'property_uri', 'reference_uri', 'reference_supporting_text', 'reference_date'])\n",
      "attribute nodes: dict_keys(['id', 'semantic_groups', 'preflabel', 'name', 'synonyms', 'description'])\n"
     ]
    }
   ],
   "source": [
    "# print type of objects\n",
    "print('type edges:', type(reg_edges))\n",
    "print('type nodes:', type(reg_nodes))\n",
    "print()\n",
    "\n",
    "# print objects sizes\n",
    "print('len edges:', len(reg_edges))\n",
    "print('len nodes:', len(reg_nodes))\n",
    "print()\n",
    "\n",
    "# print object attribute\n",
    "print('attribute edges:', reg_edges[0].keys())\n",
    "print('attribute nodes:', reg_nodes[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading and concatenating all curated statements in the network...\n",
      "\n",
      "* Curation edge files concatenated shape: (322, 22)\n",
      "\n",
      "Reading and concatenating all curated nodes in the network...\n",
      "\n",
      "* Curation node files concatenated shape: (318, 9)\n",
      "\n",
      "Preparing curated network...\n",
      "\n",
      "Drop duplicated rows...\n",
      "Before drop: 322\n",
      "After drop: 321\n",
      "\n",
      "Save curated network at curation/...\n",
      "Curated edges data structure shape: (321, 9)\n",
      "Curated edges data structure fields: Index(['subject_id', 'property_id', 'object_id', 'reference_uri',\n",
      "       'reference_supporting_text', 'reference_date', 'property_label',\n",
      "       'property_description', 'property_uri'],\n",
      "      dtype='object')\n",
      "\n",
      "Preparing curated nodes...\n",
      "\n",
      "Drop duplicated rows...\n",
      "Before drop: 318\n",
      "After drop: 288\n",
      "\n",
      "Save curated nodes at curation/...\n",
      "Curated nodes data structure shape: (288, 5)\n",
      "Curated nodes data structure fields: Index(['id', 'semantic_groups', 'preflabel', 'synonyms', 'description'], dtype='object')\n",
      "\n",
      "ID conversion: from ngly1 curated network to graph schema...\n",
      "\n",
      "Mapping genes to HGNC ID...\n",
      "querying 1-18...done.\n",
      "Finished.\n",
      "\n",
      "Adding diseases to MONDO ID network...\n",
      "\n",
      "Adding gene to protein network...\n",
      "querying 1-43...done.\n",
      "Finished.\n",
      "\n",
      "Drop duplicated gene-protein relations...\n",
      "\n",
      "Mapping genes to HGNC ID...\n",
      "querying 1-18...done.\n",
      "Finished.\n",
      "\n",
      "Adding diseases described by the MONDO ontology...\n",
      "\n",
      "Adding Name attribute: gene names from BioThings...\n",
      "querying 1-298...done.\n",
      "Finished.\n",
      "38 input query terms found dup hits:\n",
      "\t[('or', 5), ('NGLY1', 3), ('of', 16), ('1', 14), ('by', 9), ('MRS', 9), ('CSF', 8), ('acid', 4), ('B\n",
      "591 input query terms found no hit:\n",
      "\t['NGLY1-deficiency', 'misfolded', 'incompletely', 'synthesized', 'protein', 'catabolic', 'process', \n",
      "Pass \"returnall=True\" to return complete lists of duplicate or missing query terms.\n",
      "\n",
      "Preparing encoding genes from ngly1 curated network...\n",
      "\n",
      "Adding BioThings annotation: gene symbol, name, synonyms, description...\n",
      "querying 1-43...done.\n",
      "Finished.\n",
      "\n",
      "Save curated graph edges file at graph/...\n",
      "\n",
      "* This is the size of the edges file data structure: (362, 10)\n",
      "* These are the edges attributes: Index(['g2p_mark', 'object_id', 'property_description', 'property_id',\n",
      "       'property_label', 'property_uri', 'reference_date',\n",
      "       'reference_supporting_text', 'reference_uri', 'subject_id'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "  g2p_mark     object_id property_description property_id property_label  \\\n",
      "0        0  DOID:0060728                  NaN  RO:0002200  has phenotype   \n",
      "\n",
      "  property_uri reference_date  \\\n",
      "0          NaN     2016-07-07   \n",
      "\n",
      "                           reference_supporting_text  \\\n",
      "0  NGLY1 deficiency (OMIM 610661 and 615273), or ...   \n",
      "\n",
      "                                  reference_uri  subject_id  \n",
      "0  https://www.ncbi.nlm.nih.gov/pubmed/27388694  HGNC:17646  \n",
      "\n",
      "Save curated graph nodes file at graph/...\n",
      "\n",
      "* This is the size of the nodes file data structure: (302, 6)\n",
      "* These are the nodes attributes: Index(['description', 'id', 'name', 'preflabel', 'semantic_groups',\n",
      "       'synonyms'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "     description            id name         preflabel semantic_groups  \\\n",
      "0  Human disease  DOID:0060728  NaN  NGLY1-deficiency            DISO   \n",
      "\n",
      "                                            synonyms  \n",
      "0  congenital disorder of deglycosylation|congeni...  \n",
      "CPU times: user 2.8 s, sys: 620 ms, total: 3.42 s\n",
      "Wall time: 9.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# graph v3.2\n",
    "# read network from drive and concat all curated statements\n",
    "curation_edges, curation_nodes = curation.read_network(version='v20180118')\n",
    "\n",
    "# prepare data edges and nodes\n",
    "data_edges = curation.prepare_data_edges(curation_edges)\n",
    "data_nodes = curation.prepare_data_nodes(curation_nodes)\n",
    "\n",
    "# prepare curated edges and nodes\n",
    "curated_network = curation.prepare_curated_edges(data_edges)\n",
    "curated_concepts = curation.prepare_curated_nodes(data_nodes)\n",
    "\n",
    "\n",
    "# build edges and nodes files\n",
    "curation_edges = curation.build_edges(curated_network)\n",
    "curation_nodes = curation.build_nodes(curated_concepts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network is returned as both CSV file and digital object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type edges: <class 'list'>\n",
      "type nodes: <class 'list'>\n",
      "\n",
      "len edges: 362\n",
      "len nodes: 302\n",
      "\n",
      "attribute edges: dict_keys(['subject_id', 'object_id', 'property_id', 'property_label', 'property_description', 'property_uri', 'reference_uri', 'reference_supporting_text', 'reference_date', 'g2p_mark'])\n",
      "attribute nodes: dict_keys(['id', 'semantic_groups', 'preflabel', 'name', 'synonyms', 'description'])\n"
     ]
    }
   ],
   "source": [
    "# print type of objects\n",
    "print('type edges:', type(curation_edges))\n",
    "print('type nodes:', type(curation_nodes))\n",
    "print()\n",
    "\n",
    "# print objects sizes\n",
    "print('len edges:', len(curation_edges))\n",
    "print('len nodes:', len(curation_nodes))\n",
    "print()\n",
    "\n",
    "# print object attribute\n",
    "print('attribute edges:', curation_edges[0].keys())\n",
    "print('attribute nodes:', curation_nodes[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import monarch\n",
    "We retrieved edges from Monarch using the monarch module:\n",
    "\n",
    "    - From 8 seed nodes we retrieved 1st shell\n",
    "    - From all seed and 1 shell nodes we retrieved edges among them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The function \"get_neighbours_list()\" is running, please keep calm and have some coffee...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:20<00:00,  2.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished get_neighbours...\n",
      "705\n",
      "\n",
      "The function \"get_orthopheno_list()\" is running, please keep calm and have some coffee...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:22<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished get_neighbours...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [01:26<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished get_neighbours...\n",
      "240\n",
      "\n",
      "The function \"get_orthopheno_list()\" is running, please keep calm and have some coffee...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 705/705 [1:36:08<00:00,  5.23s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished get_neighbours...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1497/1497 [32:32<00:00,  1.53it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished get_neighbours...\n",
      "4411\n",
      "genelist:  5364\n",
      "\n",
      "The function \"extract_edges()\" is running, please keep calm and have some coffee...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5086/5086 [5:39:15<00:00,  5.03s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished get_connections...\n",
      "network:  36187\n",
      "\n",
      "File '/home/nuria/workspace/graph-hypothesis-generation-lib/plan/monarch/monarch_connections_v2019-03-10.csv' saved.\n",
      "df (36187, 9)\n",
      "\n",
      "* This is the size of the edges file data structure: (36187, 9)\n",
      "* These are the edges attributes: Index(['object_id', 'property_description', 'property_id', 'property_label',\n",
      "       'property_uri', 'reference_date', 'reference_supporting_text',\n",
      "       'reference_uri', 'subject_id'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "        object_id property_description property_id property_label  \\\n",
      "0  UBERON:0010307                   NA  RO:0002206   expressed in   \n",
      "\n",
      "                                property_uri reference_date  \\\n",
      "0  http://purl.obolibrary.org/obo/RO_0002206             NA   \n",
      "\n",
      "                           reference_supporting_text reference_uri  \\\n",
      "0  This edge comes from the Monarch Knowledge Gra...            NA   \n",
      "\n",
      "    subject_id  \n",
      "0  MGI:1344333  \n",
      "Number of concepts: 5086\n",
      "Number of nodes CURIEs: 30\n",
      "List of nodes CURIEs: dict_keys(['MGI', 'UBERON', 'NCBIGene', 'RGD', 'GO', 'WormBase', 'ZFIN', 'FlyBase', 'FBbt', 'HGNC', 'SGD', 'HP', 'Xenbase', 'MONARCH', 'KEGG-path', 'ZP', 'WBPhenotype', 'FBcv', 'MONDO', 'REACT', 'CL', 'Coriell', 'OMIM', 'MP', '', 'ClinVarVariant', 'ENSEMBL', 'AQTLTrait', 'MMRRC', 'APO'])\n",
      "\n",
      "Adding BioThings annotation: gene name, synonyms, description...\n",
      "symbols: 1724\n",
      "querying 1-1000...done.\n",
      "querying 1001-1724...done.\n",
      "Finished.\n",
      "312 input query terms found dup hits:\n",
      "\t[('Mid2', 2), ('Cd6', 2), ('CD6', 6), ('Fbxw11', 2), ('Fbxo6', 2), ('Aqp1', 2), ('Traf2', 2), ('EGFR\n",
      "52 input query terms found no hit:\n",
      "\t['T19D2.1', 'Aqp1<tm1Ask>/Aqp1<tm1Ask>', '[involves:', 'C57BL/6J', '*', 'CD-1]', 'CABZ01053588.1', '\n",
      "Pass \"returnall=True\" to return complete lists of duplicate or missing query terms.\n",
      "\n",
      "* This is the size of the nodes file data structure: (5086, 6)\n",
      "* These are the nodes attributes: Index(['description', 'id', 'name', 'preflabel', 'semantic_groups',\n",
      "       'synonyms'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "                                         description           id       name  \\\n",
      "0  The protein encoded by this gene is a member o...  MGI:1344333  midline 2   \n",
      "\n",
      "  preflabel semantic_groups                 synonyms  \n",
      "0      Mid2            GENE  FXY2|MRX101|RNF60|TRIM1  \n",
      "CPU times: user 10min 31s, sys: 42.8 s, total: 11min 13s\n",
      "Wall time: 7h 50min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# prepare data to graph schema\n",
    "# seed nodes\n",
    "seedList = [ \n",
    "    'MONDO:0014109', # NGLY1 deficiency\n",
    "    'HGNC:17646', # NGLY1 human gene\n",
    "    'HGNC:633', # AQP1 human gene\n",
    "    'MGI:103201', # AQP1 mouse gene\n",
    "    'HGNC:7781', # NRF1 human gene* Ginger: known as NFE2L1. http://biogps.org/#goto=genereport&id=4779\n",
    "    'HGNC:24622', # ENGASE human gene\n",
    "    'HGNC:636', # AQP3 human gene\n",
    "    'HGNC:19940' # AQP11 human gene\n",
    "] \n",
    "\n",
    "# get first shell of neighbours\n",
    "neighboursList = monarch.get_neighbours_list(seedList)\n",
    "print(len(neighboursList))\n",
    "\n",
    "# introduce animal model ortho-phenotypes for seed and 1st shell neighbors\n",
    "seed_orthophenoList = monarch.get_orthopheno_list(seedList)\n",
    "print(len(seed_orthophenoList))\n",
    "neighbours_orthophenoList = monarch.get_orthopheno_list(neighboursList)\n",
    "print(len(neighbours_orthophenoList))\n",
    "\n",
    "# network nodes: seed + 1shell + ortholog-phentoype\n",
    "geneList = sum([seedList,\n",
    "                neighboursList,\n",
    "                seed_orthophenoList,\n",
    "                neighbours_orthophenoList], \n",
    "               [])\n",
    "print('genelist: ',len(geneList))\n",
    "\n",
    "# get Monarch network\n",
    "monarch_network = monarch.extract_edges(geneList)\n",
    "print('network: ',len(monarch_network))\n",
    "\n",
    "# save edges\n",
    "monarch.print_network(monarch_network, 'monarch_connections')\n",
    "\n",
    "# build network with graph schema #!!!#\n",
    "monarch_edges = monarch.build_edges(monarch_network)\n",
    "monarch_nodes = monarch.build_nodes(monarch_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type edges: <class 'list'>\n",
      "type nodes: <class 'list'>\n",
      "\n",
      "len edges: 36187\n",
      "len nodes: 5086\n",
      "\n",
      "attribute edges: dict_keys(['subject_id', 'object_id', 'property_id', 'property_label', 'property_description', 'property_uri', 'reference_uri', 'reference_supporting_text', 'reference_date'])\n",
      "attribute nodes: dict_keys(['id', 'semantic_groups', 'preflabel', 'name', 'synonyms', 'description'])\n"
     ]
    }
   ],
   "source": [
    "# print type of objects\n",
    "print('type edges:', type(monarch_edges))\n",
    "print('type nodes:', type(monarch_nodes))\n",
    "print()\n",
    "\n",
    "# print objects sizes\n",
    "print('len edges:', len(monarch_edges))\n",
    "print('len nodes:', len(monarch_nodes))\n",
    "print()\n",
    "\n",
    "# print object attribute\n",
    "print('attribute edges:', monarch_edges[0].keys())\n",
    "print('attribute nodes:', monarch_nodes[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Network is returned as both CSV file and digital object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph library\n",
    "### Create the review knowledge graph\n",
    "#### import graph\n",
    "\n",
    "Tasks:\n",
    "\n",
    "* Load Networks and calculate graph nodes\n",
    "* Monarch graph connectivity\n",
    "* Build graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curated:\n",
      "(362, 10)\n",
      "Index(['g2p_mark', 'object_id', 'property_description', 'property_id',\n",
      "       'property_label', 'property_uri', 'reference_date',\n",
      "       'reference_supporting_text', 'reference_uri', 'subject_id'],\n",
      "      dtype='object')\n",
      "Monarch:\n",
      "(36187, 9)\n",
      "Index(['object_id', 'property_description', 'property_id', 'property_label',\n",
      "       'property_uri', 'reference_date', 'reference_supporting_text',\n",
      "       'reference_uri', 'subject_id'],\n",
      "      dtype='object')\n",
      "Transcriptomics:\n",
      "(386, 9)\n",
      "Index(['object_id', 'property_description', 'property_id', 'property_label',\n",
      "       'property_uri', 'reference_date', 'reference_supporting_text',\n",
      "       'reference_uri', 'subject_id'],\n",
      "      dtype='object')\n",
      "Regulatory:\n",
      "(197267, 9)\n",
      "Index(['object_id', 'property_description', 'property_id', 'property_label',\n",
      "       'property_uri', 'reference_date', 'reference_supporting_text',\n",
      "       'reference_uri', 'subject_id'],\n",
      "      dtype='object')\n",
      "\n",
      "Concatenating into a graph...\n",
      "(36935, 9)\n",
      "\n",
      "Drop duplicated rows...\n",
      "(36935, 9)\n",
      "\n",
      "Merging tf-gene network to the graph...\n",
      "(9795, 9)\n",
      "\n",
      "Saving tf merged edges...\n",
      "(46730, 9)\n",
      "\n",
      "Drop duplicated rows...\n",
      "(46730, 9)\n",
      "\n",
      "Generating graph nodes...\n",
      "(9808, 1)\n",
      "\n",
      "The function \"extract_edges()\" is running, please keep calm and have some coffee...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9808/9808 [10:19:57<00:00,  3.15s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished get_connections...\n",
      "network:  236374\n",
      "\n",
      "File '/home/nuria/workspace/graph-hypothesis-generation-lib/plan/monarch/monarch_connections_graph_v2019-03-10.csv' saved.\n",
      "df (236374, 9)\n",
      "\n",
      "* This is the size of the edges file data structure: (236374, 9)\n",
      "* These are the edges attributes: Index(['object_id', 'property_description', 'property_id', 'property_label',\n",
      "       'property_uri', 'reference_date', 'reference_supporting_text',\n",
      "       'reference_uri', 'subject_id'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "    object_id property_description property_id  property_label  \\\n",
      "0  HGNC:19986                   NA  RO:0002434  interacts with   \n",
      "\n",
      "                                property_uri reference_date  \\\n",
      "0  http://purl.obolibrary.org/obo/RO_0002434             NA   \n",
      "\n",
      "                           reference_supporting_text reference_uri  subject_id  \n",
      "0  This edge comes from the Monarch Knowledge Gra...            NA  HGNC:12590  \n",
      "Number of concepts: 9466\n",
      "Number of nodes CURIEs: 30\n",
      "List of nodes CURIEs: dict_keys(['HGNC', 'UBERON', 'GO', 'NCBIGene', 'HP', 'FlyBase', 'FBcv', 'SGD', 'MGI', 'CL', 'RGD', 'ZFIN', 'FBbt', 'KEGG-path', 'MONDO', 'Xenbase', 'WormBase', 'OMIM', 'REACT', 'MP', 'MONARCH', 'ClinVarVariant', 'Coriell', '', 'ZP', 'WBPhenotype', 'ENSEMBL', 'AQTLTrait', 'APO', 'MMRRC'])\n",
      "\n",
      "Adding BioThings annotation: gene name, synonyms, description...\n",
      "symbols: 6017\n",
      "querying 1-1000...done.\n",
      "querying 1001-2000...done.\n",
      "querying 2001-3000...done.\n",
      "querying 3001-4000...done.\n",
      "querying 4001-5000...done.\n",
      "querying 5001-6000...done.\n",
      "querying 6001-6017...done.\n",
      "Finished.\n",
      "316 input query terms found dup hits:\n",
      "\t[('MTUS2', 6), ('UBC', 4), ('PUS7', 2), ('SRPK2', 7), ('Srpk2', 2), ('FSD2', 8), ('APP', 4), ('Aqp9'\n",
      "53 input query terms found no hit:\n",
      "\t['ENSEMBL:ENSRNOG00000047531', 'Slc14a1<tm1Ask>/Slc14a1<tm1Ask>;', 'Aqp1<tm1Ask>/Aqp1<tm1Ask>', '[in\n",
      "Pass \"returnall=True\" to return complete lists of duplicate or missing query terms.\n",
      "\n",
      "* This is the size of the nodes file data structure: (9466, 6)\n",
      "* These are the nodes attributes: Index(['description', 'id', 'name', 'preflabel', 'semantic_groups',\n",
      "       'synonyms'],\n",
      "      dtype='object')\n",
      "* This is the first record:\n",
      "  description          id                                            name  \\\n",
      "0          NA  HGNC:12590  ubiquinol-cytochrome c reductase hinge protein   \n",
      "\n",
      "  preflabel semantic_groups    synonyms  \n",
      "0     UQCRH            GENE  QCR6|UQCR8  \n",
      "\n",
      "Preparing networks...\n",
      "Curated:\n",
      "(362, 10)\n",
      "Index(['g2p_mark', 'object_id', 'property_description', 'property_id',\n",
      "       'property_label', 'property_uri', 'reference_date',\n",
      "       'reference_supporting_text', 'reference_uri', 'subject_id'],\n",
      "      dtype='object')\n",
      "Monarch:\n",
      "(236374, 9)\n",
      "Index(['object_id', 'property_description', 'property_id', 'property_label',\n",
      "       'property_uri', 'reference_date', 'reference_supporting_text',\n",
      "       'reference_uri', 'subject_id'],\n",
      "      dtype='object')\n",
      "Transcriptomics:\n",
      "(386, 9)\n",
      "Index(['object_id', 'property_description', 'property_id', 'property_label',\n",
      "       'property_uri', 'reference_date', 'reference_supporting_text',\n",
      "       'reference_uri', 'subject_id'],\n",
      "      dtype='object')\n",
      "Regulatory:\n",
      "(9795, 9)\n",
      "Index(['subject_id', 'property_id', 'object_id', 'reference_uri',\n",
      "       'reference_supporting_text', 'reference_date', 'property_label',\n",
      "       'property_description', 'property_uri'],\n",
      "      dtype='object')\n",
      "\n",
      "Concatenating into a graph...\n",
      "(246917, 9)\n",
      "\n",
      "Drop duplicated rows...\n",
      "(246917, 9)\n",
      "\n",
      "Saving final graph...\n",
      "(246917, 9)\n",
      "Index(['subject_id', 'property_id', 'object_id', 'reference_uri',\n",
      "       'reference_supporting_text', 'reference_date', 'property_label',\n",
      "       'property_description', 'property_uri'],\n",
      "      dtype='object')\n",
      "\n",
      "Preparing networks...\n",
      "Curated:\n",
      "(302, 6)\n",
      "Index(['description', 'id', 'name', 'preflabel', 'semantic_groups',\n",
      "       'synonyms'],\n",
      "      dtype='object')\n",
      "Monarch:\n",
      "(9466, 6)\n",
      "Index(['description', 'id', 'name', 'preflabel', 'semantic_groups',\n",
      "       'synonyms'],\n",
      "      dtype='object')\n",
      "Transcriptomics:\n",
      "(386, 6)\n",
      "Index(['description', 'id', 'name', 'preflabel', 'semantic_groups',\n",
      "       'synonyms'],\n",
      "      dtype='object')\n",
      "Regulatory:\n",
      "(16963, 6)\n",
      "Index(['description', 'id', 'name', 'preflabel', 'semantic_groups',\n",
      "       'synonyms'],\n",
      "      dtype='object')\n",
      "\n",
      "Annotating nodes in the graph...\n",
      "graph from e (9808, 1)\n",
      "annotation check\n",
      "curated (302, 6)\n",
      "monarch (9466, 6)\n",
      "rna (386, 6)\n",
      "regulation (4234, 6)\n",
      "\n",
      "Concatenating all nodes...\n",
      "graph ann (14388, 6)\n",
      "diff set()\n",
      "\n",
      "Drop duplicated rows...\n",
      "(11525, 6)\n",
      "\n",
      "Drop duplicated nodes...\n",
      "(9808, 6)\n",
      "\n",
      "All graph nodes are annotated.\n",
      "Regulation nodes not in the graph: 12729\n",
      "\n",
      "Saving final graph...\n",
      "(9808, 6)\n",
      "Index(['id', 'semantic_groups', 'preflabel', 'synonyms', 'name',\n",
      "       'description'],\n",
      "      dtype='object')\n",
      "CPU times: user 15min 13s, sys: 53.6 s, total: 16min 7s\n",
      "Wall time: 10h 21min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# load networks and calculate graph nodes\n",
    "graph_nodes_list, reg_graph_edges = graph.graph_nodes(\n",
    "    curation=curation_edges,\n",
    "    monarch=monarch_edges,\n",
    "    transcriptomics=rna_edges,\n",
    "    regulation=reg_edges\n",
    ")\n",
    "\n",
    "# monarch graph connectivity\n",
    "# get Monarch edges\n",
    "monarch_network_graph = monarch.extract_edges(graph_nodes_list)\n",
    "print('network: ',len(monarch_network_graph))\n",
    "\n",
    "# save network\n",
    "monarch.print_network(monarch_network_graph, 'monarch_connections_graph')\n",
    "\n",
    "# build Monarch graph network\n",
    "monarch_graph_edges = monarch.build_edges(monarch_network_graph)\n",
    "monarch_graph_nodes = monarch.build_nodes(monarch_network_graph)\n",
    "\n",
    "# build graph\n",
    "edges = graph.build_edges(\n",
    "    curation=curation_edges,\n",
    "    monarch=monarch_graph_edges,\n",
    "    transcriptomics=rna_edges,\n",
    "    regulation=reg_graph_edges\n",
    ")\n",
    "nodes = graph.build_nodes(\n",
    "    statements=edges,\n",
    "    curation=curation_nodes,\n",
    "    monarch=monarch_graph_nodes,\n",
    "    transcriptomics=rna_nodes,\n",
    "    regulation=reg_nodes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type edges: <class 'pandas.core.frame.DataFrame'>\n",
      "type nodes: <class 'pandas.core.frame.DataFrame'>\n",
      "\n",
      "len edges: 246917\n",
      "len nodes: 9808\n",
      "\n",
      "attribute edges: Index(['subject_id', 'property_id', 'object_id', 'reference_uri',\n",
      "       'reference_supporting_text', 'reference_date', 'property_label',\n",
      "       'property_description', 'property_uri'],\n",
      "      dtype='object')\n",
      "attribute nodes: Index(['id', 'semantic_groups', 'preflabel', 'synonyms', 'name',\n",
      "       'description'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# print type of objects\n",
    "print('type edges:', type(edges))\n",
    "print('type nodes:', type(nodes))\n",
    "print()\n",
    "\n",
    "# print objects sizes\n",
    "print('len edges:', len(edges))\n",
    "print('len nodes:', len(nodes))\n",
    "print()\n",
    "\n",
    "# print object attribute\n",
    "print('attribute edges:', edges.columns)\n",
    "print('attribute nodes:', nodes.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neo4jlib library\n",
    "### Import the graph into Neo4j graph database\n",
    "#### import neo4jlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statements:  246917\n",
      "concepts:  9808\n",
      "\n",
      "File './neo4j-community-3.0.3/import/ngly1/ngly1_statements.csv' saved.\n",
      "\n",
      "File './neo4j-community-3.0.3/import/ngly1/ngly1_concepts.csv' saved.\n",
      "\n",
      "The graph is imported into the server. The server is running.\n",
      "\n",
      "CPU times: user 3.42 s, sys: 220 ms, total: 3.64 s\n",
      "Wall time: 11.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# import to graph interface, by now neo4j\n",
    "## get edges and files for neo4j\n",
    "edges_df = utils.get_dataframe(edges)\n",
    "nodes_df = utils.get_dataframe(nodes)\n",
    "statements = neo4jlib.get_statements(edges_df)\n",
    "concepts = neo4jlib.get_concepts(nodes_df)\n",
    "print('statements: ', len(statements))\n",
    "print('concepts: ',len(concepts))\n",
    "\n",
    "## import the graph into neo4j\n",
    "# save files into neo4j import dir\n",
    "neo4j_path = './neo4j-community-3.0.3'\n",
    "neo4jlib.save_neo4j_files(statements, neo4j_path, file_type = 'statements')\n",
    "neo4jlib.save_neo4j_files(concepts, neo4j_path, file_type = 'concepts')\n",
    "\n",
    "# import graph into neo4j\n",
    "neo4jlib.do_import(neo4j_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type edges: <class 'pandas.core.frame.DataFrame'>\n",
      "type nodes: <class 'pandas.core.frame.DataFrame'>\n",
      "\n",
      "len edges: 246917\n",
      "len nodes: 9808\n",
      "\n",
      "attribute edges: Index([':START_ID', ':TYPE', ':END_ID', 'reference_uri',\n",
      "       'reference_supporting_text', 'reference_date', 'property_label',\n",
      "       'property_description:IGNORE', 'property_uri'],\n",
      "      dtype='object')\n",
      "attribute nodes: Index(['id:ID', ':LABEL', 'preflabel', 'synonyms:IGNORE', 'name',\n",
      "       'description'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# print type of objects\n",
    "print('type edges:', type(statements))\n",
    "print('type nodes:', type(concepts))\n",
    "print()\n",
    "\n",
    "# print objects sizes\n",
    "print('len edges:', len(statements))\n",
    "print('len nodes:', len(concepts))\n",
    "print()\n",
    "\n",
    "# print object attribute\n",
    "print('attribute edges:', statements.columns)\n",
    "print('attribute nodes:', concepts.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hypothesis-generation library\n",
    "### Query the graph for mechanistic explanation, then summarize the extracted paths\n",
    "#### import hypothesis, summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ortopheno query with general nodes/relations removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Hypothesis generator has finished. 2 QUERIES completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 405 ms, sys: 32.4 ms, total: 438 ms\n",
      "Wall time: 5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get orthopheno paths\n",
    "seed = list([\n",
    "        'HGNC:17646',  # NGLY1 human gene\n",
    "        'HGNC:633'  # AQP1 human gene\n",
    "])\n",
    "hypothesis.query(seed,queryname='ngly1_aqp1',port='7687') #http_port= 7470; bolt_port=7680"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Hypothesis generator has finished. 2 QUERIES completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.73 s, sys: 38.1 ms, total: 2.77 s\n",
      "Wall time: 5.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get orthopheno paths\n",
    "seed = list([\n",
    "        'HGNC:17646',  # NGLY1 human gene\n",
    "        'HGNC:633'  # AQP1 human gene\n",
    "])\n",
    "hypothesis.query(seed, queryname='ngly1_aqp1', pwdegree='1000', phdegree='1000', port='7687')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Hypothesis generator has finished. 2 QUERIES completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.19 s, sys: 75.7 ms, total: 8.27 s\n",
      "Wall time: 8.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import hypothesis\n",
    "# get orthopheno paths\n",
    "seed = list([\n",
    "        'HGNC:17646',  # NGLY1 human gene\n",
    "        'HGNC:633'  # AQP1 human gene\n",
    "])\n",
    "hypothesis.open_query(seed,queryname='ngly1_aqp1',port='7687')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File '/home/nuria/workspace/graph-hypothesis-generation-lib/plan/summaries/query_ngly1_aqp1_paths_source:HGNC:17646_target:HGNC:633_summary_metapaths_v2019-03-10.csv' saved.\n",
      "\n",
      "File '/home/nuria/workspace/graph-hypothesis-generation-lib/plan/summaries/query_ngly1_aqp1_paths_source:HGNC:17646_target:HGNC:633_summary_entities_in_metapaths_v2019-03-10.csv' saved.\n",
      "\n",
      "File '/home/nuria/workspace/graph-hypothesis-generation-lib/plan/summaries/query_ngly1_aqp1_paths_source:HGNC:633_target:HGNC:17646_summary_metapaths_v2019-03-10.csv' saved.\n",
      "\n",
      "File '/home/nuria/workspace/graph-hypothesis-generation-lib/plan/summaries/query_ngly1_aqp1_paths_source:HGNC:633_target:HGNC:17646_summary_entities_in_metapaths_v2019-03-10.csv' saved.\n",
      "\n",
      "File '/home/nuria/workspace/graph-hypothesis-generation-lib/plan/summaries/monarch_orthopeno_network_query_source:HGNC:17646_target:HGNC:633_summary_nodes_v2019-03-10.csv' saved.\n",
      "\n",
      "File '/home/nuria/workspace/graph-hypothesis-generation-lib/plan/summaries/monarch_orthopeno_network_query_source:HGNC:633_target:HGNC:17646_summary_nodes_v2019-03-10.csv' saved.\n",
      "\n",
      "File '/home/nuria/workspace/graph-hypothesis-generation-lib/plan/summaries/monarch_orthopeno_network_query_source:HGNC:17646_target:HGNC:633_summary_node_types_v2019-03-10.csv' saved.\n",
      "\n",
      "File '/home/nuria/workspace/graph-hypothesis-generation-lib/plan/summaries/monarch_orthopeno_network_query_source:HGNC:633_target:HGNC:17646_summary_node_types_v2019-03-10.csv' saved.\n",
      "\n",
      "File '/home/nuria/workspace/graph-hypothesis-generation-lib/plan/summaries/monarch_orthopeno_network_query_source:HGNC:17646_target:HGNC:633_summary_edges_v2019-03-10.csv' saved.\n",
      "\n",
      "File '/home/nuria/workspace/graph-hypothesis-generation-lib/plan/summaries/monarch_orthopeno_network_query_source:HGNC:633_target:HGNC:17646_summary_edges_v2019-03-10.csv' saved.\n",
      "\n",
      "File '/home/nuria/workspace/graph-hypothesis-generation-lib/plan/summaries/monarch_orthopeno_network_query_source:HGNC:17646_target:HGNC:633_summary_edge_types_v2019-03-10.csv' saved.\n",
      "\n",
      "File '/home/nuria/workspace/graph-hypothesis-generation-lib/plan/summaries/monarch_orthopeno_network_query_source:HGNC:633_target:HGNC:17646_summary_edge_types_v2019-03-10.csv' saved.\n",
      "CPU times: user 2min 12s, sys: 1.02 ms, total: 2min 12s\n",
      "Wall time: 2min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# get summary\n",
    "data = summary.path_load('./hypothesis/query_ngly1_aqp1_paths_v2019-03-10')\n",
    "\n",
    "#parse data for summarization\n",
    "data_parsed = list()\n",
    "#funcs = [summary.metapaths, summary.nodes, summary.node_types, summary.edges, summary.edge_types]\n",
    "for query in data:\n",
    "    query_parsed = summary.query_parser(query)\n",
    "    #metapath(query_parsed)\n",
    "    #map(lambda x: x(query_parsed), funcs)\n",
    "    data_parsed.append(query_parsed)\n",
    "summary.metapaths(data_parsed)\n",
    "summary.nodes(data_parsed)\n",
    "summary.node_types(data_parsed)\n",
    "summary.edges(data_parsed)\n",
    "summary.edge_types(data_parsed)\n",
    "#for query in data_parsed:\n",
    "#    map(lambda x: x(query), funcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
